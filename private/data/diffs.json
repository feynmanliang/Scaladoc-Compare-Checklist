[
    {
        "add": [
            ">             (class)ChiSqTestResult(class)KolmogorovSmirnovTestResult(trait)TestResult"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/ClassificationModel.html.raw:", 
        "location": "130c134", 
        "remove": [
            "<             (class)ChiSqTestResult(trait)TestResult"
        ]
    }, 
    {
        "add": [
            ">           DecisionTreeClassificationModel, LogisticRegressionModel, NaiveBayesModel, RandomForestClassificationModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/ClassificationModel.html.raw:", 
        "location": "29c29", 
        "remove": [
            "<           LogisticRegressionModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/ClassificationModel.html.raw:", 
        "location": "1019c1019,1021", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/ClassificationModel.html.raw:", 
        "location": "1023,1026c1025", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/Classifier.html.raw:", 
        "location": "1177a1177,1189", 
        "remove": []
    }, 
    {
        "add": [
            ">           DecisionTreeClassifier, LogisticRegression, NaiveBayes, RandomForestClassifier"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/Classifier.html.raw:", 
        "location": "29c29", 
        "remove": [
            "<           LogisticRegression"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/Classifier.html.raw:", 
        "location": "1012c1012,1014", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1016,1019c1018", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         DecisionTreeClassificationModel extends ProbabilisticClassificationModel[Vector, DecisionTreeClassificationModel] with DecisionTreeModel with Serializable"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "14c14", 
        "remove": [
            "<         DecisionTreeClassificationModel extends PredictionModel[Vector, DecisionTreeClassificationModel] with DecisionTreeModel with Serializable"
        ]
    }, 
    {
        "add": [
            ">           DecisionTreeModel, ProbabilisticClassificationModel[Vector, DecisionTreeClassificationModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, ClassificationModel[Vector, DecisionTreeClassificationModel], ClassifierParams, HasRawPredictionCol, PredictionModel[Vector, DecisionTreeClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[DecisionTreeClassificationModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "27c27", 
        "remove": [
            "<           DecisionTreeModel, PredictionModel[Vector, DecisionTreeClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[DecisionTreeClassificationModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   DecisionTreeClassificationModelDecisionTreeModelProbabilisticClassificationModelProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassificationModelClassifierParamsHasRawPredictionColPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "45c45", 
        "remove": [
            "<                   DecisionTreeClassificationModelDecisionTreeModelPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">               Instance Constructors", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         new", 
            ">", 
            ">", 
            ">         DecisionTreeClassificationModel(rootNode: Node, numClasses: Int)", 
            ">", 
            ">", 
            ">       Construct a decision tree classification model.Construct a decision tree classification model.rootNodeRoot node of tree, with other nodes attached.", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "63a64,80", 
        "remove": []
    }, 
    {
        "add": [
            ">         getProbabilityCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getRawPredictionCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "506a524,562", 
        "remove": []
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         numClasses: Int", 
            ">", 
            ">", 
            ">       Number of classes (values which the label can take).Number of classes (values which the label can take). Definition ClassesDecisionTreeClassificationModel \u2192 ClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "816a873,885", 
        "remove": []
    }, 
    {
        "add": [
            "> This internal method is used to implement transform() and output predictionCol.This default implementation for classification predicts the index of the maximum value", 
            "> from predictRaw().", 
            ">  Attributesprotected Definition ClassesDecisionTreeClassificationModel \u2192 ClassificationModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictProbability(features: Vector): Vector", 
            ">", 
            ">", 
            ">       Predict the probability of each class given the features.Predict the probability of each class given the features.", 
            "> These predictions are also called class conditional probabilities.This internal method is used to implement transform() and output probabilityCol.", 
            "> returnsEstimated class conditional probabilities", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictRaw(features: Vector): Vector", 
            ">", 
            ">", 
            ">       Raw prediction for each possible label.Raw prediction for each possible label.", 
            "> The meaning of a \"raw\" prediction may vary between algorithms, but it intuitively gives", 
            "> a measure of confidence in each possible label (where larger = more confident).", 
            "> This internal method is used to implement transform() and output rawPredictionCol.", 
            "> returnsvector where element i is the raw prediction for label i.", 
            ">          This raw prediction may be any real number, where a larger value indicates greater", 
            ">          confidence for that label.", 
            ">  Attributesprotected Definition ClassesDecisionTreeClassificationModel \u2192 ClassificationModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "868,869c937,975", 
        "remove": [
            "< This internal method is used to implement transform() and output predictionCol.", 
            "<  Attributesprotected Definition ClassesDecisionTreeClassificationModel \u2192 PredictionModel"
        ]
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         probability2prediction(probability: Vector): Double", 
            ">", 
            ">", 
            ">       Given a vector of class conditional probabilities, select the predicted label.Given a vector of class conditional probabilities, select the predicted label.", 
            "> This supports thresholds which favor particular labels.returnspredicted label", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         probabilityCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for Column name for predicted class conditional probabilities.Param for Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.. Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2prediction(rawPrediction: Vector): Double", 
            ">", 
            ">", 
            ">       Given a vector of raw predictions, select the predicted label.Given a vector of raw predictions, select the predicted label.", 
            "> This may be overridden to support thresholds which favor particular labels.returnspredicted label", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel \u2192 ClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2probability(rawPrediction: Vector): Vector", 
            ">", 
            ">", 
            ">       Non-in-place version of raw2probabilityInPlace()Non-in-place version of raw2probabilityInPlace() Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2probabilityInPlace(rawPrediction: Vector): Vector", 
            ">", 
            ">", 
            ">       Estimate the probability of each class given the raw prediction,", 
            "> doing the computation in-place.Estimate the probability of each class given the raw prediction,", 
            "> doing the computation in-place.", 
            "> These predictions are also called class conditional probabilities.This internal method is used to implement transform() and output probabilityCol.", 
            "> returnsEstimated class conditional probabilities (modified input vector)", 
            ">  Attributesprotected Definition ClassesDecisionTreeClassificationModel \u2192 ProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         rawPredictionCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for raw prediction (a.Param for raw prediction (a.k.a. confidence) column name. Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "888a995,1081", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "950c1143,1145", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "954,957c1149", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setProbabilityCol(value: String): DecisionTreeClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setRawPredictionCol(value: String): DecisionTreeClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): DecisionTreeClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1017a1210,1248", 
        "remove": []
    }, 
    {
        "add": [
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         thresholds: DoubleArrayParam", 
            ">", 
            ">", 
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1030a1262,1274", 
        "remove": []
    }, 
    {
        "add": [
            ">       Transforms dataset by reading from featuresCol, and appending new columns as specified by", 
            "> parameters:Transforms dataset by reading from featuresCol, and appending new columns as specified by", 
            "> parameters:predicted labels as predictionCol of type Doubleraw predictions (confidences) as rawPredictionCol of type Vectorprobability of each class as probabilityCol of type Vector.", 
            "> datasetinput datasetreturnstransformed dataset", 
            ">  Definition ClassesProbabilisticClassificationModel \u2192 ClassificationModel \u2192 PredictionModel \u2192 Transformer"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1064,1068c1308,1312", 
        "remove": [
            "<       Transforms dataset by reading from featuresCol, calling predict(), and storing", 
            "< the predictions as a new column predictionCol.Transforms dataset by reading from featuresCol, calling predict(), and storing", 
            "< the predictions as a new column predictionCol.", 
            "< datasetinput datasetreturnstransformed dataset with predictionCol of type Double", 
            "<  Definition ClassesPredictionModel \u2192 Transformer"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1108a1353,1365", 
        "remove": []
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesProbabilisticClassifierParams \u2192 ClassifierParams \u2192 PredictorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassificationModel.html.raw:", 
        "location": "1160c1417", 
        "remove": [
            "<  Attributesprotected Definition ClassesPredictorParams"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ProbabilisticClassificationModel[Vector, DecisionTreeClassificationModel]", 
            ">", 
            ">               Inherited from ProbabilisticClassifierParams", 
            ">", 
            ">               Inherited from HasThresholds", 
            ">", 
            ">               Inherited from HasProbabilityCol", 
            ">", 
            ">               Inherited from ClassificationModel[Vector, DecisionTreeClassificationModel]", 
            ">", 
            ">               Inherited from ClassifierParams", 
            ">", 
            ">               Inherited from HasRawPredictionCol", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1247a1505,1518", 
        "remove": []
    }, 
    {
        "add": [
            ">         DecisionTreeClassifier extends ProbabilisticClassifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel] with DecisionTreeParams with TreeClassifierParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "14c14", 
        "remove": [
            "<         DecisionTreeClassifier extends Predictor[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel] with DecisionTreeParams with TreeClassifierParams"
        ]
    }, 
    {
        "add": [
            ">           TreeClassifierParams, DecisionTreeParams, ProbabilisticClassifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, Classifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel], ClassifierParams, HasRawPredictionCol, Predictor[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[DecisionTreeClassificationModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           TreeClassifierParams, DecisionTreeParams, Predictor[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[DecisionTreeClassificationModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   DecisionTreeClassifierTreeClassifierParamsDecisionTreeParamsProbabilisticClassifierProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassifierClassifierParamsHasRawPredictionColPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "46c46", 
        "remove": [
            "<                   DecisionTreeClassifierTreeClassifierParamsDecisionTreeParamsPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         getProbabilityCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getRawPredictionCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "727a728,766", 
        "remove": []
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         probabilityCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for Column name for predicted class conditional probabilities.Param for Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.. Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         rawPredictionCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for raw prediction (a.Param for raw prediction (a.k.a. confidence) column name. Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1145a1185,1210", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1220c1285,1287", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1224,1227c1291", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setProbabilityCol(value: String): DecisionTreeClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setRawPredictionCol(value: String): DecisionTreeClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): DecisionTreeClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1364a1429,1467", 
        "remove": []
    }, 
    {
        "add": [
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         thresholds: DoubleArrayParam", 
            ">", 
            ">", 
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1377a1481,1493", 
        "remove": []
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesProbabilisticClassifierParams \u2192 ClassifierParams \u2192 PredictorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/DecisionTreeClassifier.html.raw:", 
        "location": "1463c1579", 
        "remove": [
            "<  Attributesprotected Definition ClassesPredictorParams"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ProbabilisticClassifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel]", 
            ">", 
            ">               Inherited from ProbabilisticClassifierParams", 
            ">", 
            ">               Inherited from HasThresholds", 
            ">", 
            ">               Inherited from HasProbabilityCol", 
            ">", 
            ">               Inherited from Classifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel]", 
            ">", 
            ">               Inherited from ClassifierParams", 
            ">", 
            ">               Inherited from HasRawPredictionCol", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/GBTClassificationModel.html.raw:", 
        "location": "1552a1669,1682", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/GBTClassificationModel.html.raw:", 
        "location": "939c939,941", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/GBTClassificationModel.html.raw:", 
        "location": "943,946c945", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesGBTClassificationModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/GBTClassifier.html.raw:", 
        "location": "1110a1110,1122", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/GBTClassifier.html.raw:", 
        "location": "1326c1326,1328", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1330,1333c1332", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           LogisticRegressionParams, HasStandardization, HasTol, HasFitIntercept, HasMaxIter, HasElasticNetParam, HasRegParam, ProbabilisticClassifier[Vector, LogisticRegression, LogisticRegressionModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, Classifier[Vector, LogisticRegression, LogisticRegressionModel], ClassifierParams, HasRawPredictionCol, Predictor[Vector, LogisticRegression, LogisticRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[LogisticRegressionModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "26c26", 
        "remove": [
            "<           LogisticRegressionParams, HasThreshold, HasTol, HasFitIntercept, HasMaxIter, HasElasticNetParam, HasRegParam, ProbabilisticClassifier[Vector, LogisticRegression, LogisticRegressionModel], ProbabilisticClassifierParams, HasProbabilityCol, Classifier[Vector, LogisticRegression, LogisticRegressionModel], ClassifierParams, HasRawPredictionCol, Predictor[Vector, LogisticRegression, LogisticRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[LogisticRegressionModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LogisticRegressionLogisticRegressionParamsHasStandardizationHasTolHasFitInterceptHasMaxIterHasElasticNetParamHasRegParamProbabilisticClassifierProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassifierClassifierParamsHasRawPredictionColPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "44c44", 
        "remove": [
            "<                   LogisticRegressionLogisticRegressionParamsHasThresholdHasTolHasFitInterceptHasMaxIterHasElasticNetParamHasRegParamProbabilisticClassifierProbabilisticClassifierParamsHasProbabilityColClassifierClassifierParamsHasRawPredictionColPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         getStandardization: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "691a692,704", 
        "remove": []
    }, 
    {
        "add": [
            ">       Version of getThresholds() for binary classification, available for backwards", 
            "> compatibility.Version of getThresholds() for binary classification, available for backwards", 
            "> compatibility.Param thresholds must have length 2 (or not be specified).", 
            "> This returns <span class=\"num\">1</span> / (<span class=\"num\">1</span> + thresholds(<span class=\"num\">0</span>) / thresholds(<span class=\"num\">1</span>)).", 
            "> 1 / (1 + thresholds(0) / thresholds(1))", 
            "> }}} Definition ClassesLogisticRegression \u2192 LogisticRegressionParams", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "695c708,726", 
        "remove": [
            "<        Definition ClassesHasThreshold"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1144c1175,1177", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1148,1151c1181", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         setStandardization(value: Boolean): LogisticRegression.this.type", 
            ">", 
            ">", 
            ">       Whether to standardize the training features before fitting the model.Whether to standardize the training features before fitting the model.", 
            "> The coefficients of models will be always returned on the original scale,", 
            "> so it will be transparent for users. Note that with/without standardization,", 
            "> the models should be always converged to the same solution when no regularization", 
            "> is applied. In R's GLMNET package, the default behavior is true as well.", 
            "> Default is true.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1298a1329,1346", 
        "remove": []
    }, 
    {
        "add": [
            ">       Version of setThresholds() for binary classification, available for backwards", 
            "> compatibility.Version of setThresholds() for binary classification, available for backwards", 
            "> compatibility.Calling this with threshold p will effectively call setThresholds(Array(1-p, p)).Default is effectively 0.5. Definition ClassesLogisticRegression \u2192 LogisticRegressionParams", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): LogisticRegression", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1301a1350,1363", 
        "remove": []
    }, 
    {
        "add": [
            ">        Definition ClassesProbabilisticClassifier"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1302a1365", 
        "remove": []
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         standardization: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to standardize the training features before fitting the model.Param for whether to standardize the training features before fitting the model.. Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1323a1387,1399", 
        "remove": []
    }, 
    {
        "add": [
            ">         thresholds: DoubleArrayParam"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1340c1416", 
        "remove": [
            "<         threshold: DoubleParam"
        ]
    }, 
    {
        "add": [
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1343c1419", 
        "remove": [
            "<       Param for threshold in binary classification prediction, in range [0, 1].Param for threshold in binary classification prediction, in range [0, 1]. Definition ClassesHasThreshold"
        ]
    }, 
    {
        "add": [
            ">               Inherited from HasStandardization"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegression.html.raw:", 
        "location": "1535c1611", 
        "remove": [
            "<               Inherited from HasThreshold"
        ]
    }, 
    {
        "add": [
            ">               Inherited from HasThresholds", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1550a1627,1628", 
        "remove": []
    }, 
    {
        "add": [
            ">           LogisticRegressionParams, HasStandardization, HasTol, HasFitIntercept, HasMaxIter, HasElasticNetParam, HasRegParam, ProbabilisticClassificationModel[Vector, LogisticRegressionModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, ClassificationModel[Vector, LogisticRegressionModel], ClassifierParams, HasRawPredictionCol, PredictionModel[Vector, LogisticRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[LogisticRegressionModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "25c25", 
        "remove": [
            "<           LogisticRegressionParams, HasThreshold, HasTol, HasFitIntercept, HasMaxIter, HasElasticNetParam, HasRegParam, ProbabilisticClassificationModel[Vector, LogisticRegressionModel], ProbabilisticClassifierParams, HasProbabilityCol, ClassificationModel[Vector, LogisticRegressionModel], ClassifierParams, HasRawPredictionCol, PredictionModel[Vector, LogisticRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[LogisticRegressionModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LogisticRegressionModelLogisticRegressionParamsHasStandardizationHasTolHasFitInterceptHasMaxIterHasElasticNetParamHasRegParamProbabilisticClassificationModelProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassificationModelClassifierParamsHasRawPredictionColPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "43c43", 
        "remove": [
            "<                   LogisticRegressionModelLogisticRegressionParamsHasThresholdHasTolHasFitInterceptHasMaxIterHasElasticNetParamHasRegParamProbabilisticClassificationModelProbabilisticClassifierParamsHasProbabilityColClassificationModelClassifierParamsHasRawPredictionColPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         getStandardization: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "593a594,606", 
        "remove": []
    }, 
    {
        "add": [
            ">       Version of getThresholds() for binary classification, available for backwards", 
            "> compatibility.Version of getThresholds() for binary classification, available for backwards", 
            "> compatibility.Param thresholds must have length 2 (or not be specified).", 
            "> This returns <span class=\"num\">1</span> / (<span class=\"num\">1</span> + thresholds(<span class=\"num\">0</span>) / thresholds(<span class=\"num\">1</span>)).", 
            "> 1 / (1 + thresholds(0) / thresholds(1))", 
            "> }}} Definition ClassesLogisticRegressionModel \u2192 LogisticRegressionParams", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "597c610,628", 
        "remove": [
            "<        Definition ClassesHasThreshold"
        ]
    }, 
    {
        "add": [
            "> The behavior of this can be adjusted using thresholds."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1007c1038", 
        "remove": [
            "< The behavior of this can be adjusted using threshold."
        ]
    }, 
    {
        "add": [
            "> This supports thresholds which favor particular labels.returnspredicted label"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1071c1102", 
        "remove": [
            "< This may be overridden to support thresholds which favor particular labels.returnspredicted label"
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesLogisticRegressionModel \u2192 ProbabilisticClassificationModel \u2192 ClassificationModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1100c1131", 
        "remove": [
            "<  Attributesprotected Definition ClassesLogisticRegressionModel \u2192 ClassificationModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1212c1243,1245", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1216,1219c1249", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Version of setThresholds() for binary classification, available for backwards", 
            "> compatibility.Version of setThresholds() for binary classification, available for backwards", 
            "> compatibility.Calling this with threshold p will effectively call setThresholds(Array(1-p, p)).Default is effectively 0.5. Definition ClassesLogisticRegressionModel \u2192 LogisticRegressionParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1312a1343,1345", 
        "remove": []
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): LogisticRegressionModel", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         standardization: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to standardize the training features before fitting the model.Param for whether to standardize the training features before fitting the model.. Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1318a1352,1376", 
        "remove": []
    }, 
    {
        "add": [
            ">         thresholds: DoubleArrayParam"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1336c1394", 
        "remove": [
            "<         threshold: DoubleParam"
        ]
    }, 
    {
        "add": [
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1339c1397", 
        "remove": [
            "<       Param for threshold in binary classification prediction, in range [0, 1].Param for threshold in binary classification prediction, in range [0, 1]. Definition ClassesHasThreshold"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1422a1481,1493", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from HasStandardization"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/LogisticRegressionModel.html.raw:", 
        "location": "1575c1646", 
        "remove": [
            "<               Inherited from HasThreshold"
        ]
    }, 
    {
        "add": [
            ">               Inherited from HasThresholds", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRest.html.raw:", 
        "location": "1590a1662,1663", 
        "remove": []
    }, 
    {
        "add": [
            ">       param for the base binary classifier that we reduce multiclass classification into.param for the base binary classifier that we reduce multiclass classification into.", 
            "> The base classifier input and output columns are ignored in favor of", 
            "> the ones specified in OneVsRest. Definition ClassesOneVsRestParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRest.html.raw:", 
        "location": "220c220,222", 
        "remove": [
            "<       param for the base binary classifier that we reduce multiclass classification into.param for the base binary classifier that we reduce multiclass classification into. Definition ClassesOneVsRestParams"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRest.html.raw:", 
        "location": "1003c1005,1007", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRest.html.raw:", 
        "location": "1007,1010c1011", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setFeaturesCol(value: String): OneVsRest.this.type", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setLabelCol(value: String): OneVsRest.this.type", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setPredictionCol(value: String): OneVsRest.this.type", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRestModel.html.raw:", 
        "location": "1030a1032,1070", 
        "remove": []
    }, 
    {
        "add": [
            ">       param for the base binary classifier that we reduce multiclass classification into.param for the base binary classifier that we reduce multiclass classification into.", 
            "> The base classifier input and output columns are ignored in favor of", 
            "> the ones specified in OneVsRest. Definition ClassesOneVsRestParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRestModel.html.raw:", 
        "location": "191c191,193", 
        "remove": [
            "<       param for the base binary classifier that we reduce multiclass classification into.param for the base binary classifier that we reduce multiclass classification into. Definition ClassesOneVsRestParams"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/OneVsRestModel.html.raw:", 
        "location": "938c940,942", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/package.html.raw:", 
        "location": "942,945c946", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         DecisionTreeClassificationModel extends ProbabilisticClassificationModel[Vector, DecisionTreeClassificationModel] with DecisionTreeModel with Serializable"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/package.html.raw:", 
        "location": "72c72", 
        "remove": [
            "<         DecisionTreeClassificationModel extends PredictionModel[Vector, DecisionTreeClassificationModel] with DecisionTreeModel with Serializable"
        ]
    }, 
    {
        "add": [
            ">         DecisionTreeClassifier extends ProbabilisticClassifier[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel] with DecisionTreeParams with TreeClassifierParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/package.html.raw:", 
        "location": "86c86", 
        "remove": [
            "<         DecisionTreeClassifier extends Predictor[Vector, DecisionTreeClassifier, DecisionTreeClassificationModel] with DecisionTreeParams with TreeClassifierParams"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         MultilayerPerceptronClassifier extends Predictor[Vector, MultilayerPerceptronClassifier, MultilayerPerceptronClassifierModel] with MultilayerPerceptronParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Classifier trainer based on the Multilayer Perceptron.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         MultilayerPerceptronClassifierModel extends PredictionModel[Vector, MultilayerPerceptronClassifierModel] with Serializable", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Classifier model based on the Multilayer Perceptron.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         NaiveBayes extends ProbabilisticClassifier[Vector, NaiveBayes, NaiveBayesModel] with NaiveBayesParams", 
            ">", 
            ">", 
            ">       Naive Bayes Classifiers.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         NaiveBayesModel extends ProbabilisticClassificationModel[Vector, NaiveBayesModel] with NaiveBayesParams", 
            ">", 
            ">", 
            ">       Model produced by NaiveBayes", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/package.html.raw:", 
        "location": "154a155,209", 
        "remove": []
    }, 
    {
        "add": [
            ">         RandomForestClassificationModel extends ProbabilisticClassificationModel[Vector, RandomForestClassificationModel] with TreeEnsembleModel with Serializable"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/package.html.raw:", 
        "location": "186c241", 
        "remove": [
            "<         RandomForestClassificationModel extends PredictionModel[Vector, RandomForestClassificationModel] with TreeEnsembleModel with Serializable"
        ]
    }, 
    {
        "add": [
            ">         RandomForestClassifier extends ProbabilisticClassifier[Vector, RandomForestClassifier, RandomForestClassificationModel] with RandomForestParams with TreeClassifierParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "200c255", 
        "remove": [
            "<         RandomForestClassifier extends Predictor[Vector, RandomForestClassifier, RandomForestClassificationModel] with RandomForestParams with TreeClassifierParams"
        ]
    }, 
    {
        "add": [
            ">         RandomForestClassificationModel extends ProbabilisticClassificationModel[Vector, RandomForestClassificationModel] with TreeEnsembleModel with Serializable"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "14c14", 
        "remove": [
            "<         RandomForestClassificationModel extends PredictionModel[Vector, RandomForestClassificationModel] with TreeEnsembleModel with Serializable"
        ]
    }, 
    {
        "add": [
            ">           TreeEnsembleModel, ProbabilisticClassificationModel[Vector, RandomForestClassificationModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, ClassificationModel[Vector, RandomForestClassificationModel], ClassifierParams, HasRawPredictionCol, PredictionModel[Vector, RandomForestClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[RandomForestClassificationModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "26c26", 
        "remove": [
            "<           TreeEnsembleModel, PredictionModel[Vector, RandomForestClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[RandomForestClassificationModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   RandomForestClassificationModelTreeEnsembleModelProbabilisticClassificationModelProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassificationModelClassifierParamsHasRawPredictionColPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "44c44", 
        "remove": [
            "<                   RandomForestClassificationModelTreeEnsembleModelPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">               Instance Constructors", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         new", 
            ">", 
            ">", 
            ">         RandomForestClassificationModel(trees: Array[DecisionTreeClassificationModel], numFeatures: Int, numClasses: Int)", 
            ">", 
            ">", 
            ">       Construct a random forest classification model, with all trees weighted equally.Construct a random forest classification model, with all trees weighted equally.treesComponent trees", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "62a63,79", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         lazy val", 
            ">", 
            ">", 
            ">         featureImportances: Vector", 
            ">", 
            ">", 
            ">       Estimate of the importance of each feature.Estimate of the importance of each feature.This generalizes the idea of \"Gini\" importance to other losses,", 
            "> following the explanation of Gini importance from \"Random Forests\" documentation", 
            "> by Leo Breiman and Adele Cutler, and following the implementation from scikit-learn.This feature importance is calculated as follows:Average over trees:importance(feature j) = sum (over nodes which split on feature j) of the gain,", 
            ">       where gain is scaled by the number of instances passing through nodeNormalize importances for tree based on total number of training instances used", 
            ">       to build tree.Normalize feature importance vector to sum to 1.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "331a349,366", 
        "remove": []
    }, 
    {
        "add": [
            ">         getProbabilityCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getRawPredictionCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "490a526,564", 
        "remove": []
    }, 
    {
        "add": [
            ">         numClasses: Int", 
            ">", 
            ">", 
            ">       Number of classes (values which the label can take).Number of classes (values which the label can take). Definition ClassesRandomForestClassificationModel \u2192 ClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         numFeatures: Int", 
            ">", 
            ">", 
            ">       Number of features used by this model", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "803a878,904", 
        "remove": []
    }, 
    {
        "add": [
            "> This internal method is used to implement transform() and output predictionCol.This default implementation for classification predicts the index of the maximum value", 
            "> from predictRaw().", 
            ">  Attributesprotected Definition ClassesClassificationModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictProbability(features: Vector): Vector", 
            ">", 
            ">", 
            ">       Predict the probability of each class given the features.Predict the probability of each class given the features.", 
            "> These predictions are also called class conditional probabilities.This internal method is used to implement transform() and output probabilityCol.", 
            "> returnsEstimated class conditional probabilities", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictRaw(features: Vector): Vector", 
            ">", 
            ">", 
            ">       Raw prediction for each possible label.Raw prediction for each possible label.", 
            "> The meaning of a \"raw\" prediction may vary between algorithms, but it intuitively gives", 
            "> a measure of confidence in each possible label (where larger = more confident).", 
            "> This internal method is used to implement transform() and output rawPredictionCol.", 
            "> returnsvector where element i is the raw prediction for label i.", 
            ">          This raw prediction may be any real number, where a larger value indicates greater", 
            ">          confidence for that label.", 
            ">  Attributesprotected Definition ClassesRandomForestClassificationModel \u2192 ClassificationModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "852,853c953,991", 
        "remove": [
            "< This internal method is used to implement transform() and output predictionCol.", 
            "<  Attributesprotected Definition ClassesRandomForestClassificationModel \u2192 PredictionModel"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         probability2prediction(probability: Vector): Double", 
            ">", 
            ">", 
            ">       Given a vector of class conditional probabilities, select the predicted label.Given a vector of class conditional probabilities, select the predicted label.", 
            "> This supports thresholds which favor particular labels.returnspredicted label", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         probabilityCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for Column name for predicted class conditional probabilities.Param for Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.. Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2prediction(rawPrediction: Vector): Double", 
            ">", 
            ">", 
            ">       Given a vector of raw predictions, select the predicted label.Given a vector of raw predictions, select the predicted label.", 
            "> This may be overridden to support thresholds which favor particular labels.returnspredicted label", 
            ">  Attributesprotected Definition ClassesProbabilisticClassificationModel \u2192 ClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2probability(rawPrediction: Vector): Vector", 
            ">", 
            ">", 
            ">       Non-in-place version of raw2probabilityInPlace()Non-in-place version of raw2probabilityInPlace() Attributesprotected Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         raw2probabilityInPlace(rawPrediction: Vector): Vector", 
            ">", 
            ">", 
            ">       Estimate the probability of each class given the raw prediction,", 
            "> doing the computation in-place.Estimate the probability of each class given the raw prediction,", 
            "> doing the computation in-place.", 
            "> These predictions are also called class conditional probabilities.This internal method is used to implement transform() and output probabilityCol.", 
            "> returnsEstimated class conditional probabilities (modified input vector)", 
            ">  Attributesprotected Definition ClassesRandomForestClassificationModel \u2192 ProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         rawPredictionCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for raw prediction (a.Param for raw prediction (a.k.a. confidence) column name. Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "871a1010,1096", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "921c1146,1148", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "925,928c1152", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setProbabilityCol(value: String): RandomForestClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setRawPredictionCol(value: String): RandomForestClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): RandomForestClassificationModel", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassificationModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "988a1213,1251", 
        "remove": []
    }, 
    {
        "add": [
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         thresholds: DoubleArrayParam", 
            ">", 
            ">", 
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "1001a1265,1277", 
        "remove": []
    }, 
    {
        "add": [
            ">       Transforms dataset by reading from featuresCol, and appending new columns as specified by", 
            "> parameters:Transforms dataset by reading from featuresCol, and appending new columns as specified by", 
            "> parameters:predicted labels as predictionCol of type Doubleraw predictions (confidences) as rawPredictionCol of type Vectorprobability of each class as probabilityCol of type Vector.", 
            "> datasetinput datasetreturnstransformed dataset", 
            ">  Definition ClassesProbabilisticClassificationModel \u2192 ClassificationModel \u2192 PredictionModel \u2192 Transformer"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "1048,1052c1324,1328", 
        "remove": [
            "<       Transforms dataset by reading from featuresCol, calling predict(), and storing", 
            "< the predictions as a new column predictionCol.Transforms dataset by reading from featuresCol, calling predict(), and storing", 
            "< the predictions as a new column predictionCol.", 
            "< datasetinput datasetreturnstransformed dataset with predictionCol of type Double", 
            "<  Definition ClassesPredictionModel \u2192 Transformer"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesRandomForestClassificationModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "1092a1369,1381", 
        "remove": []
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesProbabilisticClassifierParams \u2192 ClassifierParams \u2192 PredictorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassificationModel.html.raw:", 
        "location": "1170c1459", 
        "remove": [
            "<  Attributesprotected Definition ClassesPredictorParams"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ProbabilisticClassificationModel[Vector, RandomForestClassificationModel]", 
            ">", 
            ">               Inherited from ProbabilisticClassifierParams", 
            ">", 
            ">               Inherited from HasThresholds", 
            ">", 
            ">               Inherited from HasProbabilityCol", 
            ">", 
            ">               Inherited from ClassificationModel[Vector, RandomForestClassificationModel]", 
            ">", 
            ">               Inherited from ClassifierParams", 
            ">", 
            ">               Inherited from HasRawPredictionCol", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1257a1547,1560", 
        "remove": []
    }, 
    {
        "add": [
            ">         RandomForestClassifier extends ProbabilisticClassifier[Vector, RandomForestClassifier, RandomForestClassificationModel] with RandomForestParams with TreeClassifierParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "14c14", 
        "remove": [
            "<         RandomForestClassifier extends Predictor[Vector, RandomForestClassifier, RandomForestClassificationModel] with RandomForestParams with TreeClassifierParams"
        ]
    }, 
    {
        "add": [
            ">           TreeClassifierParams, RandomForestParams, TreeEnsembleParams, HasSeed, DecisionTreeParams, ProbabilisticClassifier[Vector, RandomForestClassifier, RandomForestClassificationModel], ProbabilisticClassifierParams, HasThresholds, HasProbabilityCol, Classifier[Vector, RandomForestClassifier, RandomForestClassificationModel], ClassifierParams, HasRawPredictionCol, Predictor[Vector, RandomForestClassifier, RandomForestClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[RandomForestClassificationModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           TreeClassifierParams, RandomForestParams, TreeEnsembleParams, HasSeed, DecisionTreeParams, Predictor[Vector, RandomForestClassifier, RandomForestClassificationModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[RandomForestClassificationModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   RandomForestClassifierTreeClassifierParamsRandomForestParamsTreeEnsembleParamsHasSeedDecisionTreeParamsProbabilisticClassifierProbabilisticClassifierParamsHasThresholdsHasProbabilityColClassifierClassifierParamsHasRawPredictionColPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "46c46", 
        "remove": [
            "<                   RandomForestClassifierTreeClassifierParamsRandomForestParamsTreeEnsembleParamsHasSeedDecisionTreeParamsPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         getProbabilityCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">", 
            ">         getRawPredictionCol: String", 
            ">", 
            ">", 
            ">        Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "774a775,800", 
        "remove": []
    }, 
    {
        "add": [
            ">         getThresholds: Array[Double]", 
            ">", 
            ">", 
            ">        Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "800a827,839", 
        "remove": []
    }, 
    {
        "add": [
            ">         probabilityCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for Column name for predicted class conditional probabilities.Param for Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.. Definition ClassesHasProbabilityCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         rawPredictionCol: Param[String]", 
            ">", 
            ">", 
            ">       Param for raw prediction (a.Param for raw prediction (a.k.a. confidence) column name. Definition ClassesHasRawPredictionCol", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         val", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1237a1277,1302", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1322c1387,1389", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1326,1329c1393", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         setProbabilityCol(value: String): RandomForestClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setRawPredictionCol(value: String): RandomForestClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1496a1561,1586", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setThresholds(value: Array[Double]): RandomForestClassifier", 
            ">", 
            ">", 
            ">        Definition ClassesProbabilisticClassifier", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1518a1609,1621", 
        "remove": []
    }, 
    {
        "add": [
            ">         final", 
            ">         val", 
            ">", 
            ">", 
            ">         thresholds: DoubleArrayParam", 
            ">", 
            ">", 
            ">       Param for Thresholds in multi-class classification to adjust the probability of predicting each class.Param for Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold.. Definition ClassesHasThresholds", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1545a1649,1661", 
        "remove": []
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesProbabilisticClassifierParams \u2192 ClassifierParams \u2192 PredictorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/classification/RandomForestClassifier.html.raw:", 
        "location": "1631c1747", 
        "remove": [
            "<  Attributesprotected Definition ClassesPredictorParams"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ProbabilisticClassifier[Vector, RandomForestClassifier, RandomForestClassificationModel]", 
            ">", 
            ">               Inherited from ProbabilisticClassifierParams", 
            ">", 
            ">               Inherited from HasThresholds", 
            ">", 
            ">               Inherited from HasProbabilityCol", 
            ">", 
            ">               Inherited from Classifier[Vector, RandomForestClassifier, RandomForestClassificationModel]", 
            ">", 
            ">               Inherited from ClassifierParams", 
            ">", 
            ">               Inherited from HasRawPredictionCol", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Estimator.html.raw:", 
        "location": "1726a1843,1856", 
        "remove": []
    }, 
    {
        "add": [
            ">           ALS, Classifier, CrossValidator, DecisionTreeClassifier, DecisionTreeRegressor, GBTClassifier, GBTRegressor, IDF, IsotonicRegression, KMeans, LinearRegression, LogisticRegression, MinMaxScaler, MultilayerPerceptronClassifier, NaiveBayes, OneVsRest, PCA, Pipeline, Predictor, RFormula, RandomForestClassifier, RandomForestRegressor, StandardScaler, StringIndexer, TrainValidationSplit, VectorIndexer, Word2Vec"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Estimator.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           ALS, Classifier, CrossValidator, DecisionTreeClassifier, DecisionTreeRegressor, GBTClassifier, GBTRegressor, IDF, LinearRegression, LogisticRegression, OneVsRest, Pipeline, Predictor, RandomForestClassifier, RandomForestRegressor, StandardScaler, StringIndexer, VectorIndexer, Word2Vec"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Estimator.html.raw:", 
        "location": "890c890,892", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html.raw:", 
        "location": "894,897c896", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            "> Evaluator for binary classification, which expects two input columns: rawPrediction and label."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html.raw:", 
        "location": "19c19", 
        "remove": [
            "< Evaluator for binary classification, which expects two input columns: score and label."
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html.raw:", 
        "location": "738c738,740", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html.raw:", 
        "location": "742,745c744", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         setRawPredictionCol(value: String): BinaryClassificationEvaluator.this.type"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html.raw:", 
        "location": "796c795", 
        "remove": [
            "<         setScoreCol(value: String): BinaryClassificationEvaluator.this.type"
        ]
    }, 
    {
        "add": [
            ">               Deprecated Value Members", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setScoreCol(value: String): BinaryClassificationEvaluator.this.type", 
            ">", 
            ">", 
            ">        Annotations", 
            ">                 @deprecated", 
            ">", 
            ">         Deprecated(Since version 1.5.0) use setRawPredictionCol instead", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/Evaluator.html.raw:", 
        "location": "920a920,938", 
        "remove": []
    }, 
    {
        "add": [
            ">           BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/Evaluator.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           BinaryClassificationEvaluator, RegressionEvaluator"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/Evaluator.html.raw:", 
        "location": "667c667,669", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/package.html.raw:", 
        "location": "671,674c673", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            "> Evaluator for binary classification, which expects two input columns: rawPrediction and label."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/package.html.raw:", 
        "location": "50c50", 
        "remove": [
            "< Evaluator for binary classification, which expects two input columns: score and label."
        ]
    }, 
    {
        "add": [
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         MulticlassClassificationEvaluator extends Evaluator with HasPredictionCol with HasLabelCol", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Evaluator for multiclass classification, which expects two input columns: score and label.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/RegressionEvaluator.html.raw:", 
        "location": "69a70,83", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/evaluation/RegressionEvaluator.html.raw:", 
        "location": "740c740,742", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Binarizer.html.raw:", 
        "location": "744,747c746", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Binarizer.html.raw:", 
        "location": "865c865,867", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Bucketizer.html.raw:", 
        "location": "869,872c871", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Bucketizer.html.raw:", 
        "location": "893c893,895", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/ElementwiseProduct.html.raw:", 
        "location": "897,900c899", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/ElementwiseProduct.html.raw:", 
        "location": "910c910,912", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/HashingTF.html.raw:", 
        "location": "914,917c916", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/HashingTF.html.raw:", 
        "location": "879c879,881", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/IDF.html.raw:", 
        "location": "883,886c885", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/IDF.html.raw:", 
        "location": "945c945,947", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/IDFModel.html.raw:", 
        "location": "949,952c951", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/IDFModel.html.raw:", 
        "location": "877c877,879", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Normalizer.html.raw:", 
        "location": "881,884c883", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Normalizer.html.raw:", 
        "location": "909c909,911", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/OneHotEncoder.html.raw:", 
        "location": "913,916c915", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/OneHotEncoder.html.raw:", 
        "location": "874c874,876", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "878,881c880", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         CountVectorizerModel extends UnaryTransformer[Seq[String], Vector, CountVectorizerModel]", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Converts a text document to a sparse vector of token counts.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         DCT extends UnaryTransformer[Vector, Vector, DCT]", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> A feature transformer that takes the 1D discrete cosine transform of a real vector.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "73a74,101", 
        "remove": []
    }, 
    {
        "add": [
            ">         MinMaxScaler extends Estimator[MinMaxScalerModel] with MinMaxScalerParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Rescale each feature individually to a common range [min, max] linearly using column summary", 
            "> statistics, which is also known as min-max normalization or Rescaling.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         MinMaxScalerModel extends Model[MinMaxScalerModel] with MinMaxScalerParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Model fitted by MinMaxScaler.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         NGram extends UnaryTransformer[Seq[String], Seq[String], NGram]", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> A feature transformer that converts the input array of strings into an array of n-grams.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "129a158,200", 
        "remove": []
    }, 
    {
        "add": [
            ">         PCA extends Estimator[PCAModel] with PCAParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> PCA trains a model to project vectors to a low-dimensional space using PCA.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         PCAModel extends Model[PCAModel] with PCAParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Model fitted by PCA.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "158a230,257", 
        "remove": []
    }, 
    {
        "add": [
            ">         RFormula extends Estimator[RFormulaModel] with RFormulaBase", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Implements the transforms required for fitting a dataset against an R model formula.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         RFormulaModel extends Model[RFormulaModel] with RFormulaBase", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> A fitted RFormula.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "172a272,299", 
        "remove": []
    }, 
    {
        "add": [
            ">         StopWordsRemover extends Transformer with HasInputCol with HasOutputCol", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> A feature transformer that filters out stop words from input.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/package.html.raw:", 
        "location": "216a344,357", 
        "remove": []
    }, 
    {
        "add": [
            ">         StringIndexerInverse extends Transformer with HasInputCol with HasOutputCol", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Transform a provided column back to the original input types using either the metadata", 
            "> on the input column, or if provided using the labels supplied by the user.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/PolynomialExpansion.html.raw:", 
        "location": "230a372,386", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/PolynomialExpansion.html.raw:", 
        "location": "913c913,915", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/RegexTokenizer.html.raw:", 
        "location": "917,920c919", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/RegexTokenizer.html.raw:", 
        "location": "966c966,968", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScaler.html.raw:", 
        "location": "970,973c972", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScaler.html.raw:", 
        "location": "920c920,922", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScalerModel.html.raw:", 
        "location": "924,927c926", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         mean: Vector", 
            ">", 
            ">", 
            ">       Mean of the StandardScalerModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScalerModel.html.raw:", 
        "location": "718a719,731", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScalerModel.html.raw:", 
        "location": "851c864,866", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StandardScalerModel.html.raw:", 
        "location": "855,858c870", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         std: Vector", 
            ">", 
            ">", 
            ">       Standard deviation of the StandardScalerModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StringIndexer.html.raw:", 
        "location": "918a931,943", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StringIndexer.html.raw:", 
        "location": "922c922,924", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StringIndexerModel.html.raw:", 
        "location": "926,929c928", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         invert(inputCol: String, outputCol: String): StringIndexerInverse", 
            ">", 
            ">", 
            ">       Return a model to perform the inverse transformation.Return a model to perform the inverse transformation.", 
            "> Note: By default we keep the original columns during this transformation, so the inverse", 
            "> should only be used on new columns such as predicted labels.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StringIndexerModel.html.raw:", 
        "location": "513a514,529", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/StringIndexerModel.html.raw:", 
        "location": "854c870,872", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Tokenizer.html.raw:", 
        "location": "858,861c876", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Tokenizer.html.raw:", 
        "location": "883c883,885", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorAssembler.html.raw:", 
        "location": "887,890c889", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorAssembler.html.raw:", 
        "location": "852c852,854", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorIndexer.html.raw:", 
        "location": "856,859c858", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorIndexer.html.raw:", 
        "location": "956c956,958", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorIndexerModel.html.raw:", 
        "location": "960,963c962", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/VectorIndexerModel.html.raw:", 
        "location": "925c925,927", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2Vec.html.raw:", 
        "location": "929,932c931", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2Vec.html.raw:", 
        "location": "1052c1052,1054", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2VecModel.html.raw:", 
        "location": "1056,1059c1058", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         findSynonyms(word: Vector, num: Int): DataFrame", 
            ">", 
            ">", 
            ">       Find \"num\" number of words closest to similarity to the given vector representation", 
            "> of the word.Find \"num\" number of words closest to similarity to the given vector representation", 
            "> of the word. Returns a dataframe with the words and the cosine similarities between the", 
            "> synonyms and the given word vector.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         findSynonyms(word: String, num: Int): DataFrame", 
            ">", 
            ">", 
            ">       Find \"num\" number of words closest in similarity to the given word.Find \"num\" number of words closest in similarity to the given word.", 
            "> Returns a dataframe with the words and the cosine similarities between the", 
            "> synonyms and the given word.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2VecModel.html.raw:", 
        "location": "349a350,382", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         getVectors: DataFrame", 
            ">", 
            ">", 
            ">       Returns a dataframe with two fields, \"word\" and \"vector\", with \"word\" being a String and", 
            "> and the vector the DenseVector that it is mapped to.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2VecModel.html.raw:", 
        "location": "522a556,569", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/feature/Word2VecModel.html.raw:", 
        "location": "983c1030,1032", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Model.html.raw:", 
        "location": "987,990c1036", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           ALSModel, Bucketizer, ClassificationModel, CrossValidatorModel, DecisionTreeClassificationModel, DecisionTreeRegressionModel, GBTClassificationModel, GBTRegressionModel, IDFModel, IsotonicRegressionModel, KMeansModel, LinearRegressionModel, LogisticRegressionModel, MinMaxScalerModel, MultilayerPerceptronClassifierModel, NaiveBayesModel, OneVsRestModel, PCAModel, PipelineModel, PredictionModel, RFormulaModel, RandomForestClassificationModel, RandomForestRegressionModel, RegressionModel, StandardScalerModel, StringIndexerModel, TrainValidationSplitModel, VectorIndexerModel, Word2VecModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Model.html.raw:", 
        "location": "29c29", 
        "remove": [
            "<           ALSModel, Bucketizer, ClassificationModel, CrossValidatorModel, DecisionTreeClassificationModel, DecisionTreeRegressionModel, GBTClassificationModel, GBTRegressionModel, IDFModel, LinearRegressionModel, LogisticRegressionModel, OneVsRestModel, PipelineModel, PredictionModel, RandomForestClassificationModel, RandomForestRegressionModel, RegressionModel, StandardScalerModel, StringIndexerModel, VectorIndexerModel, Word2VecModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Model.html.raw:", 
        "location": "867c867,869", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/package.html.raw:", 
        "location": "871,874c873", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         clustering", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         package", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/JavaParams.html.raw:", 
        "location": "230a231,243", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/JavaParams.html.raw:", 
        "location": "638c638,640", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/package.html.raw:", 
        "location": "642,645c644", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         IntArrayParam extends Param[Array[Int]]", 
            ">", 
            ">", 
            ">       :: DeveloperApi ::", 
            "> Specialized version of Param[Array[Int]] for Java.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/Param.html.raw:", 
        "location": "101a102,115", 
        "remove": []
    }, 
    {
        "add": [
            ">           BooleanParam, DoubleArrayParam, DoubleParam, FloatParam, IntArrayParam, IntParam, LongParam, StringArrayParam"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/Params.html.raw:", 
        "location": "30c30", 
        "remove": [
            "<           BooleanParam, DoubleArrayParam, DoubleParam, FloatParam, IntParam, LongParam, StringArrayParam"
        ]
    }, 
    {
        "add": [
            ">           ALS, ALSModel, Binarizer, BinaryClassificationEvaluator, Bucketizer, ClassificationModel, Classifier, CountVectorizerModel, CrossValidator, CrossValidatorModel, DCT, DecisionTreeClassificationModel, DecisionTreeClassifier, DecisionTreeRegressionModel, DecisionTreeRegressor, ElementwiseProduct, Estimator, Evaluator, GBTClassificationModel, GBTClassifier, GBTRegressionModel, GBTRegressor, HashingTF, IDF, IDFModel, IsotonicRegression, IsotonicRegressionModel, JavaParams, KMeans, KMeansModel, LinearRegression, LinearRegressionModel, LogisticRegression, LogisticRegressionModel, MinMaxScaler, MinMaxScalerModel, Model, MulticlassClassificationEvaluator, MultilayerPerceptronClassifier, MultilayerPerceptronClassifierModel, NGram, NaiveBayes, NaiveBayesModel, Normalizer, OneHotEncoder, OneVsRest, OneVsRestModel, PCA, PCAModel, Pipeline, PipelineModel, PipelineStage, PolynomialExpansion, PredictionModel, Predictor, RFormula, RFormulaModel, RandomForestClassificationModel, RandomForestClassifier, RandomForestRegressionModel, RandomForestRegressor, RegexTokenizer, RegressionEvaluator, RegressionModel, StandardScaler, StandardScalerModel, StopWordsRemover, StringIndexer, StringIndexerInverse, StringIndexerModel, Tokenizer, TrainValidationSplit, TrainValidationSplitModel, Transformer, UnaryTransformer, VectorAssembler, VectorIndexer, VectorIndexerModel, Word2Vec, Word2VecModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/Params.html.raw:", 
        "location": "29c29", 
        "remove": [
            "<           ALS, ALSModel, Binarizer, BinaryClassificationEvaluator, Bucketizer, ClassificationModel, Classifier, CrossValidator, CrossValidatorModel, DecisionTreeClassificationModel, DecisionTreeClassifier, DecisionTreeRegressionModel, DecisionTreeRegressor, ElementwiseProduct, Estimator, Evaluator, GBTClassificationModel, GBTClassifier, GBTRegressionModel, GBTRegressor, HashingTF, IDF, IDFModel, JavaParams, LinearRegression, LinearRegressionModel, LogisticRegression, LogisticRegressionModel, Model, Normalizer, OneHotEncoder, OneVsRest, OneVsRestModel, Pipeline, PipelineModel, PipelineStage, PolynomialExpansion, PredictionModel, Predictor, RandomForestClassificationModel, RandomForestClassifier, RandomForestRegressionModel, RandomForestRegressor, RegexTokenizer, RegressionEvaluator, RegressionModel, StandardScaler, StandardScalerModel, StringIndexer, StringIndexerModel, Tokenizer, Transformer, UnaryTransformer, VectorAssembler, VectorIndexer, VectorIndexerModel, Word2Vec, Word2VecModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/Params.html.raw:", 
        "location": "619c619,621", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/param/ParamValidators$.html.raw:", 
        "location": "623,626c625", 
        "remove": [
            "<  Attributesprotected Annotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         arrayLengthGt[T](lowerBound: Double): (Array[T]) \u21d2 Boolean", 
            ">", 
            ">", 
            ">       Check that the array length is greater than lowerBound.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Pipeline.html.raw:", 
        "location": "139a140,152", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Pipeline.html.raw:", 
        "location": "895c895,897", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PipelineModel.html.raw:", 
        "location": "899,902c901", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PipelineModel.html.raw:", 
        "location": "799c799,801", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PipelineStage.html.raw:", 
        "location": "803,806c805", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           ALS, ALSModel, Binarizer, Bucketizer, ClassificationModel, Classifier, CountVectorizerModel, CrossValidator, CrossValidatorModel, DCT, DecisionTreeClassificationModel, DecisionTreeClassifier, DecisionTreeRegressionModel, DecisionTreeRegressor, ElementwiseProduct, Estimator, GBTClassificationModel, GBTClassifier, GBTRegressionModel, GBTRegressor, HashingTF, IDF, IDFModel, IsotonicRegression, IsotonicRegressionModel, KMeans, KMeansModel, LinearRegression, LinearRegressionModel, LogisticRegression, LogisticRegressionModel, MinMaxScaler, MinMaxScalerModel, Model, MultilayerPerceptronClassifier, MultilayerPerceptronClassifierModel, NGram, NaiveBayes, NaiveBayesModel, Normalizer, OneHotEncoder, OneVsRest, OneVsRestModel, PCA, PCAModel, Pipeline, PipelineModel, PolynomialExpansion, PredictionModel, Predictor, RFormula, RFormulaModel, RandomForestClassificationModel, RandomForestClassifier, RandomForestRegressionModel, RandomForestRegressor, RegexTokenizer, RegressionModel, StandardScaler, StandardScalerModel, StopWordsRemover, StringIndexer, StringIndexerInverse, StringIndexerModel, Tokenizer, TrainValidationSplit, TrainValidationSplitModel, Transformer, UnaryTransformer, VectorAssembler, VectorIndexer, VectorIndexerModel, Word2Vec, Word2VecModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PipelineStage.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           ALS, ALSModel, Binarizer, Bucketizer, ClassificationModel, Classifier, CrossValidator, CrossValidatorModel, DecisionTreeClassificationModel, DecisionTreeClassifier, DecisionTreeRegressionModel, DecisionTreeRegressor, ElementwiseProduct, Estimator, GBTClassificationModel, GBTClassifier, GBTRegressionModel, GBTRegressor, HashingTF, IDF, IDFModel, LinearRegression, LinearRegressionModel, LogisticRegression, LogisticRegressionModel, Model, Normalizer, OneHotEncoder, OneVsRest, OneVsRestModel, Pipeline, PipelineModel, PolynomialExpansion, PredictionModel, Predictor, RandomForestClassificationModel, RandomForestClassifier, RandomForestRegressionModel, RandomForestRegressor, RegexTokenizer, RegressionModel, StandardScaler, StandardScalerModel, StringIndexer, StringIndexerModel, Tokenizer, Transformer, UnaryTransformer, VectorAssembler, VectorIndexer, VectorIndexerModel, Word2Vec, Word2VecModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PipelineStage.html.raw:", 
        "location": "824c824,826", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PredictionModel.html.raw:", 
        "location": "828,831c830", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           ClassificationModel, DecisionTreeClassificationModel, DecisionTreeRegressionModel, GBTClassificationModel, GBTRegressionModel, IsotonicRegressionModel, LinearRegressionModel, LogisticRegressionModel, MultilayerPerceptronClassifierModel, NaiveBayesModel, RandomForestClassificationModel, RandomForestRegressionModel, RegressionModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PredictionModel.html.raw:", 
        "location": "31c31", 
        "remove": [
            "<           ClassificationModel, DecisionTreeClassificationModel, DecisionTreeRegressionModel, GBTClassificationModel, GBTRegressionModel, LinearRegressionModel, LogisticRegressionModel, RandomForestClassificationModel, RandomForestRegressionModel, RegressionModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PredictionModel.html.raw:", 
        "location": "946c946,948", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/PredictionModel.html.raw:", 
        "location": "950,953c952", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Predictor.html.raw:", 
        "location": "1091a1091,1103", 
        "remove": []
    }, 
    {
        "add": [
            ">           Classifier, DecisionTreeClassifier, DecisionTreeRegressor, GBTClassifier, GBTRegressor, IsotonicRegression, LinearRegression, LogisticRegression, MultilayerPerceptronClassifier, NaiveBayes, RandomForestClassifier, RandomForestRegressor"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Predictor.html.raw:", 
        "location": "32c32", 
        "remove": [
            "<           Classifier, DecisionTreeClassifier, DecisionTreeRegressor, GBTClassifier, GBTRegressor, LinearRegression, LogisticRegression, RandomForestClassifier, RandomForestRegressor"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Predictor.html.raw:", 
        "location": "989c989,991", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/recommendation/ALS.html.raw:", 
        "location": "993,996c995", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/recommendation/ALS.html.raw:", 
        "location": "1270c1270,1272", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/recommendation/ALSModel.html.raw:", 
        "location": "1274,1277c1276", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/recommendation/ALSModel.html.raw:", 
        "location": "892c892,894", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressionModel.html.raw:", 
        "location": "896,899c898", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">               Instance Constructors", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         new", 
            ">", 
            ">", 
            ">         DecisionTreeRegressionModel(rootNode: Node)", 
            ">", 
            ">", 
            ">       Construct a decision tree regression model.Construct a decision tree regression model.rootNodeRoot node of tree, with other nodes attached.", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressionModel.html.raw:", 
        "location": "61a62,78", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressionModel.html.raw:", 
        "location": "950c967,969", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressionModel.html.raw:", 
        "location": "954,957c973", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressor.html.raw:", 
        "location": "1108a1125,1137", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/DecisionTreeRegressor.html.raw:", 
        "location": "1219c1219,1221", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/GBTRegressionModel.html.raw:", 
        "location": "1223,1226c1225", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/GBTRegressionModel.html.raw:", 
        "location": "937c937,939", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/GBTRegressionModel.html.raw:", 
        "location": "941,944c943", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesGBTRegressionModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/GBTRegressor.html.raw:", 
        "location": "1108a1108,1120", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/GBTRegressor.html.raw:", 
        "location": "1325c1325,1327", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1329,1332c1331", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           LinearRegressionParams, HasStandardization, HasFitIntercept, HasTol, HasMaxIter, HasElasticNetParam, HasRegParam, Regressor[Vector, LinearRegression, LinearRegressionModel], Predictor[Vector, LinearRegression, LinearRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[LinearRegressionModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "27c27", 
        "remove": [
            "<           LinearRegressionParams, HasTol, HasMaxIter, HasElasticNetParam, HasRegParam, Regressor[Vector, LinearRegression, LinearRegressionModel], Predictor[Vector, LinearRegression, LinearRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Estimator[LinearRegressionModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LinearRegressionLinearRegressionParamsHasStandardizationHasFitInterceptHasTolHasMaxIterHasElasticNetParamHasRegParamRegressorPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "45c45", 
        "remove": [
            "<                   LinearRegressionLinearRegressionParamsHasTolHasMaxIterHasElasticNetParamHasRegParamRegressorPredictorPredictorParamsHasPredictionColHasFeaturesColHasLabelColEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         fitIntercept: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to fit an intercept term.Param for whether to fit an intercept term. Definition ClassesHasFitIntercept", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "490a491,503", 
        "remove": []
    }, 
    {
        "add": [
            ">         getFitIntercept: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasFitIntercept", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "560a574,586", 
        "remove": []
    }, 
    {
        "add": [
            ">         getStandardization: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "640a667,679", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1054c1093,1095", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1058,1061c1099", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         setFitIntercept(value: Boolean): LinearRegression.this.type", 
            ">", 
            ">", 
            ">       Set if we should fit the intercept", 
            "> Default is true.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1114a1153,1166", 
        "remove": []
    }, 
    {
        "add": [
            ">         setStandardization(value: Boolean): LinearRegression.this.type", 
            ">", 
            ">", 
            ">       Whether to standardize the training features before fitting the model.Whether to standardize the training features before fitting the model.", 
            "> The coefficients of models will be always returned on the original scale,", 
            "> so it will be transparent for users. Note that with/without standardization,", 
            "> the models should be always converged to the same solution when no regularization", 
            "> is applied. In R's GLMNET package, the default behavior is true as well.", 
            "> Default is true.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1168a1221,1238", 
        "remove": []
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         standardization: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to standardize the training features before fitting the model.Param for whether to standardize the training features before fitting the model.. Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegression.html.raw:", 
        "location": "1180a1251,1263", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from HasStandardization", 
            ">", 
            ">               Inherited from HasFitIntercept", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "1378a1462,1465", 
        "remove": []
    }, 
    {
        "add": [
            ">           LinearRegressionParams, HasStandardization, HasFitIntercept, HasTol, HasMaxIter, HasElasticNetParam, HasRegParam, RegressionModel[Vector, LinearRegressionModel], PredictionModel[Vector, LinearRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[LinearRegressionModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "25c25", 
        "remove": [
            "<           LinearRegressionParams, HasTol, HasMaxIter, HasElasticNetParam, HasRegParam, RegressionModel[Vector, LinearRegressionModel], PredictionModel[Vector, LinearRegressionModel], PredictorParams, HasPredictionCol, HasFeaturesCol, HasLabelCol, Model[LinearRegressionModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LinearRegressionModelLinearRegressionParamsHasStandardizationHasFitInterceptHasTolHasMaxIterHasElasticNetParamHasRegParamRegressionModelPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "43c43", 
        "remove": [
            "<                   LinearRegressionModelLinearRegressionParamsHasTolHasMaxIterHasElasticNetParamHasRegParamRegressionModelPredictionModelPredictorParamsHasPredictionColHasFeaturesColHasLabelColModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         fitIntercept: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to fit an intercept term.Param for whether to fit an intercept term. Definition ClassesHasFitIntercept", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "391a392,404", 
        "remove": []
    }, 
    {
        "add": [
            ">         getFitIntercept: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasFitIntercept", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "461a475,487", 
        "remove": []
    }, 
    {
        "add": [
            ">         getStandardization: Boolean", 
            ">", 
            ">", 
            ">        Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "541a568,580", 
        "remove": []
    }, 
    {
        "add": [
            ">         hasSummary: Boolean", 
            ">", 
            ">", 
            ">       Indicates whether a training summary exists for this model instance.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "594a634,646", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "1011c1063,1065", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "1015,1018c1069", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         standardization: BooleanParam", 
            ">", 
            ">", 
            ">       Param for whether to standardize the training features before fitting the model.Param for whether to standardize the training features before fitting the model.. Definition ClassesHasStandardization", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         summary: LinearRegressionTrainingSummary", 
            ">", 
            ">", 
            ">       Gets summary (e.Gets summary (e.g. residuals, mse, r-squared ) of model on training set. An exception is", 
            "> thrown if trainingSummary == None.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         final"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "1079a1131,1158", 
        "remove": []
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/LinearRegressionModel.html.raw:", 
        "location": "1169a1249,1261", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from HasStandardization", 
            ">", 
            ">               Inherited from HasFitIntercept", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/package.html.raw:", 
        "location": "1321a1414,1417", 
        "remove": []
    }, 
    {
        "add": [
            ">         IsotonicRegression extends Regressor[Double, IsotonicRegression, IsotonicRegressionModel] with IsotonicRegressionParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Isotonic regression.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         IsotonicRegressionModel extends RegressionModel[Double, IsotonicRegressionModel] with IsotonicRegressionParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Model fitted by IsotonicRegression.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/package.html.raw:", 
        "location": "102a103,130", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         LinearRegressionSummary extends Serializable", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Linear regression results evaluated on a dataset.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         LinearRegressionTrainingSummary extends LinearRegressionSummary", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Linear regression training results.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "126a155,182", 
        "remove": []
    }, 
    {
        "add": [
            ">               Instance Constructors", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         new", 
            ">", 
            ">", 
            ">         RandomForestRegressionModel(trees: Array[DecisionTreeRegressionModel], numFeatures: Int)", 
            ">", 
            ">", 
            ">       Construct a random forest regression model, with all trees weighted equally.Construct a random forest regression model, with all trees weighted equally.treesComponent trees", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "61a62,78", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         lazy val", 
            ">", 
            ">", 
            ">         featureImportances: Vector", 
            ">", 
            ">", 
            ">       Estimate of the importance of each feature.Estimate of the importance of each feature.This generalizes the idea of \"Gini\" importance to other losses,", 
            "> following the explanation of Gini importance from \"Random Forests\" documentation", 
            "> by Leo Breiman and Adele Cutler, and following the implementation from scikit-learn.This feature importance is calculated as follows:Average over trees:importance(feature j) = sum (over nodes which split on feature j) of the gain,", 
            ">       where gain is scaled by the number of instances passing through nodeNormalize importances for tree based on total number of training instances used", 
            ">       to build tree.Normalize feature importance vector to sum to 1.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "330a348,365", 
        "remove": []
    }, 
    {
        "add": [
            ">         numFeatures: Int", 
            ">", 
            ">", 
            ">       Number of features used by this model", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "802a838,851", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "920c969,971", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressionModel.html.raw:", 
        "location": "924,927c975", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesRandomForestRegressionModel \u2192 PredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressor.html.raw:", 
        "location": "1091a1140,1152", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RandomForestRegressor.html.raw:", 
        "location": "1320c1320,1322", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RegressionModel.html.raw:", 
        "location": "1324,1327c1326", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           IsotonicRegressionModel, LinearRegressionModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RegressionModel.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           LinearRegressionModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RegressionModel.html.raw:", 
        "location": "943c943,945", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/regression/RegressionModel.html.raw:", 
        "location": "947,950c949", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         transformImpl(dataset: DataFrame): DataFrame", 
            ">", 
            ">", 
            ">        Attributesprotected Definition ClassesPredictionModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Transformer.html.raw:", 
        "location": "1088a1088,1100", 
        "remove": []
    }, 
    {
        "add": [
            ">           ALSModel, Binarizer, Bucketizer, ClassificationModel, CountVectorizerModel, CrossValidatorModel, DCT, DecisionTreeClassificationModel, DecisionTreeRegressionModel, ElementwiseProduct, GBTClassificationModel, GBTRegressionModel, HashingTF, IDFModel, IsotonicRegressionModel, KMeansModel, LinearRegressionModel, LogisticRegressionModel, MinMaxScalerModel, Model, MultilayerPerceptronClassifierModel, NGram, NaiveBayesModel, Normalizer, OneHotEncoder, OneVsRestModel, PCAModel, PipelineModel, PolynomialExpansion, PredictionModel, RFormulaModel, RandomForestClassificationModel, RandomForestRegressionModel, RegexTokenizer, RegressionModel, StandardScalerModel, StopWordsRemover, StringIndexerInverse, StringIndexerModel, Tokenizer, TrainValidationSplitModel, UnaryTransformer, VectorAssembler, VectorIndexerModel, Word2VecModel"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Transformer.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           ALSModel, Binarizer, Bucketizer, ClassificationModel, CrossValidatorModel, DecisionTreeClassificationModel, DecisionTreeRegressionModel, ElementwiseProduct, GBTClassificationModel, GBTRegressionModel, HashingTF, IDFModel, LinearRegressionModel, LogisticRegressionModel, Model, Normalizer, OneHotEncoder, OneVsRestModel, PipelineModel, PolynomialExpansion, PredictionModel, RandomForestClassificationModel, RandomForestRegressionModel, RegexTokenizer, RegressionModel, StandardScalerModel, StringIndexerModel, Tokenizer, UnaryTransformer, VectorAssembler, VectorIndexerModel, Word2VecModel"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/Transformer.html.raw:", 
        "location": "837c837,839", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "841,844c843", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">           CrossValidatorParams, ValidatorParams, Estimator[CrossValidatorModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "25c25", 
        "remove": [
            "<           CrossValidatorParams, Estimator[CrossValidatorModel], PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   CrossValidatorCrossValidatorParamsValidatorParamsEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "43c43", 
        "remove": [
            "<                   CrossValidatorCrossValidatorParamsEstimatorPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">       param for the estimator to be validatedparam for the estimator to be validated Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "306c306", 
        "remove": [
            "<       param for the estimator to be cross-validatedparam for the estimator to be cross-validated Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       param for estimator param mapsparam for estimator param maps Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "319c319", 
        "remove": [
            "<       param for estimator param mapsparam for estimator param maps Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       param for the evaluator used to select hyper-parameters that maximize the validated metricparam for the evaluator used to select hyper-parameters that maximize the validated metric Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "332,334c332", 
        "remove": [
            "<       param for the evaluator used to select hyper-parameters that maximize the cross-validated", 
            "< metricparam for the evaluator used to select hyper-parameters that maximize the cross-validated", 
            "< metric Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "535c533", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "548c546", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "561c559", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "974c972,974", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidator.html.raw:", 
        "location": "978,981c978", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ValidatorParams", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "1207a1205,1206", 
        "remove": []
    }, 
    {
        "add": [
            ">           CrossValidatorParams, ValidatorParams, Model[CrossValidatorModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "25c25", 
        "remove": [
            "<           CrossValidatorParams, Model[CrossValidatorModel], Transformer, PipelineStage, Logging, Params, Serializable, Serializable, Identifiable, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   CrossValidatorModelCrossValidatorParamsValidatorParamsModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "43c43", 
        "remove": [
            "<                   CrossValidatorModelCrossValidatorParamsModelTransformerPipelineStageLoggingParamsSerializableSerializableIdentifiableAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">         avgMetrics: Array[Double]", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "168a169,181", 
        "remove": []
    }, 
    {
        "add": [
            ">       param for the estimator to be validatedparam for the estimator to be validated Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "290c303", 
        "remove": [
            "<       param for the estimator to be cross-validatedparam for the estimator to be cross-validated Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       param for estimator param mapsparam for estimator param maps Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "303c316", 
        "remove": [
            "<       param for estimator param mapsparam for estimator param maps Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       param for the evaluator used to select hyper-parameters that maximize the validated metricparam for the evaluator used to select hyper-parameters that maximize the validated metric Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "316,318c329", 
        "remove": [
            "<       param for the evaluator used to select hyper-parameters that maximize the cross-validated", 
            "< metricparam for the evaluator used to select hyper-parameters that maximize the cross-validated", 
            "< metric Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "452c463", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "465c476", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesValidatorParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "478c489", 
        "remove": [
            "<        Definition ClassesCrossValidatorParams"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "919c930,932", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/CrossValidatorModel.html.raw:", 
        "location": "923,926c936", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">               Inherited from ValidatorParams", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/tuning/package.html.raw:", 
        "location": "1159a1170,1171", 
        "remove": []
    }, 
    {
        "add": [
            ">         class", 
            ">", 
            ">", 
            ">         TrainValidationSplit extends Estimator[TrainValidationSplitModel] with TrainValidationSplitParams with Logging", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Validation for hyper-parameter tuning.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         TrainValidationSplitModel extends Model[TrainValidationSplitModel] with TrainValidationSplitParams", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Model from train validation split.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/UnaryTransformer.html.raw:", 
        "location": "84a85,112", 
        "remove": []
    }, 
    {
        "add": [
            ">           CountVectorizerModel, DCT, ElementwiseProduct, NGram, Normalizer, PolynomialExpansion, RegexTokenizer, Tokenizer"
        ], 
        "filename": "1.4.2/org/apache/spark/ml/UnaryTransformer.html.raw:", 
        "location": "29c29", 
        "remove": [
            "<           ElementwiseProduct, Normalizer, PolynomialExpansion, RegexTokenizer, Tokenizer"
        ]
    }, 
    {
        "add": [
            ">       Sets default values for a list of params.Sets default values for a list of params.Note: Java developers should use the single-parameter setDefault().", 
            ">       Annotating this with varargs can cause compilation failures due to a Scala compiler bug.", 
            ">       See SPARK-9268."
        ], 
        "filename": "1.4.2/org/apache/spark/ml/UnaryTransformer.html.raw:", 
        "location": "890c890,892", 
        "remove": [
            "<       Sets default values for a list of params.Sets default values for a list of params."
        ]
    }, 
    {
        "add": [
            ">  Attributesprotected Definition ClassesParams"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/ClassificationModel.html.raw:", 
        "location": "894,897c896", 
        "remove": [
            "<  Attributesprotected Definition ClassesParamsAnnotations", 
            "<                 @varargs()", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            "> testDataarray representing a single data pointreturnspredicted category from the trained model Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/ClassificationModel.html.raw:", 
        "location": "84c84", 
        "remove": [
            "< testDataarray representing a single data pointreturnspredicted category from the trained model"
        ]
    }, 
    {
        "add": [
            "> testDataRDD representing data points to be predictedreturnsan RDD[Double] where each entry contains the corresponding prediction Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/ClassificationModel.html.raw:", 
        "location": "99c99", 
        "remove": [
            "< testDataRDD representing data points to be predictedreturnsan RDD[Double] where each entry contains the corresponding prediction"
        ]
    }, 
    {
        "add": [
            ">       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel$.html.raw:", 
        "location": "338c338", 
        "remove": [
            "<       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction"
        ]
    }, 
    {
        "add": [
            ">       scSpark context used for loading model files.", 
            "> pathPath specifying the directory to which the model was saved.", 
            "> returnsModel instance Definition ClassesLogisticRegressionModel \u2192 LoaderSince1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "257,259c257,259", 
        "remove": [
            "<       Load a model from the given path.Load a model from the given path.The model should have been saved by Saveable.save.", 
            "< scSpark context used for loading model files.pathPath specifying the directory to which the model was saved.returnsModel instance", 
            "<  Definition ClassesLogisticRegressionModel \u2192 Loader"
        ]
    }, 
    {
        "add": [
            "> It is only used for binary classification. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "192,193c192", 
        "remove": [
            "< It is only used for binary classification.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "195a195", 
        "remove": []
    }, 
    {
        "add": [
            "> It is only used for binary classification. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "302,303c302", 
        "remove": [
            "< It is only used for binary classification.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "305a305", 
        "remove": []
    }, 
    {
        "add": [
            ">       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction Definition ClassesClassificationModelSince0.8.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "429,430c429,430", 
        "remove": [
            "<       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction", 
            "<  Definition ClassesClassificationModel"
        ]
    }, 
    {
        "add": [
            ">       scSpark context used to save model data.", 
            "> pathPath specifying the directory in which to save this model.", 
            ">              If the directory already exists, this method throws an exception. Definition ClassesLogisticRegressionModel \u2192 SaveableSince1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "488,491c488,490", 
        "remove": [
            "<       Save this model to the given path.Save this model to the given path.This saves:human-readable (JSON) model metadata to path/metadata/Parquet formatted data to path/data/The model may be loaded using Loader.load.", 
            "< scSpark context used to save model data.pathPath specifying the directory in which to save this model.", 
            "<              If the directory already exists, this method throws an exception.", 
            "<  Definition ClassesLogisticRegressionModel \u2192 Saveable"
        ]
    }, 
    {
        "add": [
            "> It is only used for binary classification. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "510,511c509", 
        "remove": [
            "< It is only used for binary classification.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionModel.html.raw:", 
        "location": "513a512", 
        "remove": []
    }, 
    {
        "add": [
            ">        Definition ClassesLogisticRegressionModel \u2192 GeneralizedLinearModel \u2192 AnyRef \u2192 AnySince1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html.raw:", 
        "location": "620,621c619,620", 
        "remove": [
            "<       Print a summary of the model.Print a summary of the model.", 
            "<  Definition ClassesLogisticRegressionModel \u2192 GeneralizedLinearModel \u2192 AnyRef \u2192 Any"
        ]
    }, 
    {
        "add": [
            "> By default, it is binary logistic regression so k will be set to 2. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html.raw:", 
        "location": "644,645c644", 
        "remove": [
            "< By default, it is binary logistic regression so k will be set to 2.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithSGD$.html.raw:", 
        "location": "647a647", 
        "remove": []
    }, 
    {
        "add": [
            "> inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.returnsa LogisticRegressionModel which has the weights and offset from training. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithSGD$.html.raw:", 
        "location": "328c328", 
        "remove": [
            "< inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.returnsa LogisticRegressionModel which has the weights and offset from training."
        ]
    }, 
    {
        "add": [
            "> returnsa LogisticRegressionModel which has the weights and offset from training. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithSGD$.html.raw:", 
        "location": "347c347", 
        "remove": [
            "< returnsa LogisticRegressionModel which has the weights and offset from training."
        ]
    }, 
    {
        "add": [
            "> miniBatchFractionFraction of data to be used per iteration. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/LogisticRegressionWithSGD$.html.raw:", 
        "location": "366c366", 
        "remove": [
            "< miniBatchFractionFraction of data to be used per iteration."
        ]
    }, 
    {
        "add": [
            ">        the number of features in the data. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayes$.html.raw:", 
        "location": "386c386", 
        "remove": [
            "<        the number of features in the data."
        ]
    }, 
    {
        "add": [
            ">              multinomial or bernoulli Since0.9.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayes$.html.raw:", 
        "location": "333c333", 
        "remove": [
            "<              multinomial or bernoulli"
        ]
    }, 
    {
        "add": [
            ">              vector or a count vector.lambdaThe smoothing parameter Since0.9.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayes$.html.raw:", 
        "location": "351c351", 
        "remove": [
            "<              vector or a count vector.lambdaThe smoothing parameter"
        ]
    }, 
    {
        "add": [
            ">              vector or a count vector. Since0.9.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayesModel.html.raw:", 
        "location": "369c369", 
        "remove": [
            "<              vector or a count vector."
        ]
    }, 
    {
        "add": [
            "> testDataarray representing a single data pointreturnspredicted category from the trained model Definition ClassesNaiveBayesModel \u2192 ClassificationModelSince0.8.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayesModel.html.raw:", 
        "location": "351,352c351,352", 
        "remove": [
            "< testDataarray representing a single data pointreturnspredicted category from the trained model", 
            "<  Definition ClassesNaiveBayesModel \u2192 ClassificationModel"
        ]
    }, 
    {
        "add": [
            "> testDataRDD representing data points to be predictedreturnsan RDD[Double] where each entry contains the corresponding prediction Definition ClassesNaiveBayesModel \u2192 ClassificationModelSince0.8.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/NaiveBayesModel.html.raw:", 
        "location": "366,367c366,367", 
        "remove": [
            "< testDataRDD representing data points to be predictedreturnsan RDD[Double] where each entry contains the corresponding prediction", 
            "<  Definition ClassesNaiveBayesModel \u2192 ClassificationModel"
        ]
    }, 
    {
        "add": [
            ">       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction Definition ClassesClassificationModelSince0.8.0", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictProbabilities(testData: Vector): Vector", 
            ">", 
            ">", 
            ">       Predict posterior class probabilities for a single data point using the model trained.Predict posterior class probabilities for a single data point using the model trained.", 
            "> testDataarray representing a single data pointreturnspredicted posterior class probabilities from the trained model,", 
            ">         in the same order as class labels", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         predictProbabilities(testData: RDD[Vector]): RDD[Vector]", 
            ">", 
            ">", 
            ">       Predict values for the given data set using the model trained.Predict values for the given data set using the model trained.", 
            "> testDataRDD representing data points to be predictedreturnsan RDD[Vector] where each entry contains the predicted posterior class probabilities,", 
            ">         in the same order as class labels", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel$.html.raw:", 
        "location": "380,381c380,413", 
        "remove": [
            "<       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction", 
            "<  Definition ClassesClassificationModel"
        ]
    }, 
    {
        "add": [
            ">       scSpark context used for loading model files.", 
            "> pathPath specifying the directory to which the model was saved.", 
            "> returnsModel instance Definition ClassesSVMModel \u2192 LoaderSince1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "257,259c257,259", 
        "remove": [
            "<       Load a model from the given path.Load a model from the given path.The model should have been saved by Saveable.save.", 
            "< scSpark context used for loading model files.pathPath specifying the directory to which the model was saved.returnsModel instance", 
            "<  Definition ClassesSVMModel \u2192 Loader"
        ]
    }, 
    {
        "add": [
            "> Clears the threshold so that predict will output raw prediction scores. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "174,175c174", 
        "remove": [
            "< Clears the threshold so that predict will output raw prediction scores.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "177a177", 
        "remove": []
    }, 
    {
        "add": [
            "> Returns the threshold (if any) used for converting raw prediction scores into 0/1 predictions. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "283,284c283", 
        "remove": [
            "< Returns the threshold (if any) used for converting raw prediction scores into 0/1 predictions.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "286a286", 
        "remove": []
    }, 
    {
        "add": [
            ">       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction Definition ClassesClassificationModelSince0.8.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "379,380c379,380", 
        "remove": [
            "<       Predict values for examples stored in a JavaRDD.Predict values for examples stored in a JavaRDD.testDataJavaRDD representing data points to be predictedreturnsa JavaRDD[java.lang.Double] where each entry contains the corresponding prediction", 
            "<  Definition ClassesClassificationModel"
        ]
    }, 
    {
        "add": [
            ">       scSpark context used to save model data.", 
            "> pathPath specifying the directory in which to save this model.", 
            ">              If the directory already exists, this method throws an exception. Definition ClassesSVMModel \u2192 SaveableSince1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "438,441c438,440", 
        "remove": [
            "<       Save this model to the given path.Save this model to the given path.This saves:human-readable (JSON) model metadata to path/metadata/Parquet formatted data to path/data/The model may be loaded using Loader.load.", 
            "< scSpark context used to save model data.pathPath specifying the directory in which to save this model.", 
            "<              If the directory already exists, this method throws an exception.", 
            "<  Definition ClassesSVMModel \u2192 Saveable"
        ]
    }, 
    {
        "add": [
            "> and negative otherwise. The default value is 0.0. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "458,459c457", 
        "remove": [
            "< and negative otherwise. The default value is 0.0.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMModel.html.raw:", 
        "location": "461a460", 
        "remove": []
    }, 
    {
        "add": [
            ">        Definition ClassesSVMModel \u2192 GeneralizedLinearModel \u2192 AnyRef \u2192 AnySince1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMWithSGD$.html.raw:", 
        "location": "568,569c567,568", 
        "remove": [
            "<       Print a summary of the model.Print a summary of the model.", 
            "<  Definition ClassesSVMModel \u2192 GeneralizedLinearModel \u2192 AnyRef \u2192 Any"
        ]
    }, 
    {
        "add": [
            "> inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.returnsa SVMModel which has the weights and offset from training. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMWithSGD$.html.raw:", 
        "location": "327c327", 
        "remove": [
            "< inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.returnsa SVMModel which has the weights and offset from training."
        ]
    }, 
    {
        "add": [
            "> inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.stepSizeStep size to be used for each iteration of Gradient Descent.regParamRegularization parameter.returnsa SVMModel which has the weights and offset from training. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMWithSGD$.html.raw:", 
        "location": "345c345", 
        "remove": [
            "< inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.stepSizeStep size to be used for each iteration of Gradient Descent.regParamRegularization parameter.returnsa SVMModel which has the weights and offset from training."
        ]
    }, 
    {
        "add": [
            "> inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.stepSizeStep size to be used for each iteration of gradient descent.regParamRegularization parameter.miniBatchFractionFraction of data to be used per iteration. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/classification/SVMWithSGD$.html.raw:", 
        "location": "363c363", 
        "remove": [
            "< inputRDD of (label, array of features) pairs.numIterationsNumber of iterations of gradient descent to run.stepSizeStep size to be used for each iteration of gradient descent.regParamRegularization parameter.miniBatchFractionFraction of data to be used per iteration."
        ]
    }, 
    {
        "add": [
            ">        the number of features in the data. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "382c382", 
        "remove": [
            "<        the number of features in the data."
        ]
    }, 
    {
        "add": [
            ">           LDAModel, Saveable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "27c27", 
        "remove": [
            "<           LDAModel, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   DistributedLDAModelLDAModelSaveableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "45c45", 
        "remove": [
            "<                   DistributedLDAModelLDAModelAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">       Return the topics described by weighted terms.Return the topics described by weighted terms."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "180,182c180", 
        "remove": [
            "<       Return the topics described by weighted terms.Return the topics described by weighted terms.This limits the number of terms per topic.", 
            "< This is approximate; it may not return exactly the top-weighted terms for each topic.", 
            "< To get a more precise set of top terms, increase maxTermsPerTopic."
        ]
    }, 
    {
        "add": [
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         docConcentration: Vector", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").This is the parameter to a Dirichlet distribution.", 
            ">  Definition ClassesDistributedLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "208a207,222", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         formatVersion: String", 
            ">", 
            ">", 
            ">       Current version of model save/load format.Current version of model save/load format. Attributesprotected Definition ClassesDistributedLDAModel \u2192 Saveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         gammaShape: Double", 
            ">", 
            ">", 
            ">       Shape parameter for random initialization of variational parameter gamma.Shape parameter for random initialization of variational parameter gamma.", 
            "> Used for variational inference for perplexity and other test-time computations.", 
            ">  Attributesprotected[org.apache.spark.mllib.clustering] Definition ClassesDistributedLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "253a268,295", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         save(sc: SparkContext, path: String): Unit", 
            ">", 
            ">", 
            ">       Save this model to the given path.Save this model to the given path.This saves:human-readable (JSON) model metadata to path/metadata/Parquet formatted data to path/data/The model may be loaded using Loader.load.", 
            "> scSpark context used to save model data.pathPath specifying the directory in which to save this model.", 
            ">              If the directory already exists, this method throws an exception.", 
            ">  Definition ClassesDistributedLDAModel \u2192 Saveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "391a434,449", 
        "remove": []
    }, 
    {
        "add": [
            ">         topDocumentsPerTopic(maxDocumentsPerTopic: Int): Array[(Array[Long], Array[Double])]", 
            ">", 
            ">", 
            ">       Return the top documents for each topic", 
            "> Return the top documents for each topic", 
            "> maxDocumentsPerTopicMaximum number of documents to collect for each topic.returnsArray over topics.  Each element represent as a pair of matching arrays:", 
            ">          (IDs for the documents, weights of the topic in these documents).", 
            ">          For each topic, documents are sorted in order of decreasing topic weights.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         topTopicsPerDocument(k: Int): RDD[(Long, Array[Int], Array[Double])]", 
            ">", 
            ">", 
            ">       For each document, return the top k weighted topics for that document and their weights.For each document, return the top k weighted topics for that document and their weights.returnsRDD of (doc ID, topic indices, topic weights)", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         topicConcentration: Double", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.This is the parameter to a symmetric Dirichlet distribution.Note: The topics' distributions over terms are called \"beta\" in the original LDA paper", 
            "> by Blei et al., but are called \"phi\" in many later papers such as Asuncion et al., 2009.", 
            ">  Definition ClassesDistributedLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/DistributedLDAModel.html.raw:", 
        "location": "437a496,544", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from Saveable", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/GaussianMixtureModel.html.raw:", 
        "location": "543a651,652", 
        "remove": []
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/GaussianMixtureModel.html.raw:", 
        "location": "372,384d371", 
        "remove": [
            "<         predict(point: Vector): Int", 
            "<", 
            "<", 
            "<       Maps given point to its cluster index.", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<         def", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/KMeans.html.raw:", 
        "location": "398,410d384", 
        "remove": [
            "<         predictSoft(point: Vector): Array[Double]", 
            "<", 
            "<", 
            "<       Given the input vector, return the membership values to all mixture components.", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<", 
            "<         def", 
            "<", 
            "<"
        ]
    }, 
    {
        "add": [
            ">         setInitialModel(model: KMeansModel): KMeans.this.type", 
            ">", 
            ">", 
            ">       Set the initial starting point, bypassing the random initialization or k-means||", 
            "> The condition model.Set the initial starting point, bypassing the random initialization or k-means||", 
            "> The condition model.k == this.k must be met, failure results", 
            "> in an IllegalArgumentException.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "610a611,627", 
        "remove": []
    }, 
    {
        "add": [
            ">         getAlpha: Vector"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "238c238", 
        "remove": [
            "<         getAlpha: Double"
        ]
    }, 
    {
        "add": [
            ">         getDocConcentration: Vector"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "290c290", 
        "remove": [
            "<         getDocConcentration: Double"
        ]
    }, 
    {
        "add": [
            "> distributions over topics (\"theta\").This is the parameter to a Dirichlet distribution."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "295c295", 
        "remove": [
            "< distributions over topics (\"theta\").This is the parameter to a symmetric Dirichlet distribution."
        ]
    }, 
    {
        "add": [
            ">         setAlpha(alpha: Vector): LDA.this.type", 
            ">", 
            ">", 
            ">       Alias for setDocConcentration()", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "657a658,670", 
        "remove": []
    }, 
    {
        "add": [
            ">       Replicates Double to create a symmetric prior", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         setDocConcentration(docConcentration: Vector): LDA.this.type", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDA.html.raw:", 
        "location": "691a705,717", 
        "remove": []
    }, 
    {
        "add": [
            "> distributions over topics (\"theta\").This is the parameter to a Dirichlet distribution, where larger values mean more smoothing", 
            "> (more regularization).If set to a singleton vector Vector(-1), then docConcentration is set automatically. If set to", 
            "> singleton vector Vector(t) where t != -1, then t is replicated to a vector of length k during", 
            "> LDAOptimizer.initialize(). Otherwise, the docConcentration vector must be length k.", 
            "> (default = Vector(-1) = automatic)Optimizer-specific parameter settings:EMCurrently only supports symmetric distributions, so all values in the vector should be", 
            ">       the same.Values should be > 1.0default = uniformly (50 / k) + 1, where 50/k is common in LDA libraries and +1 follows", 
            ">       from Asuncion et al. (2009), who recommend a +1 adjustment for EM.OnlineValues should be >= 0default = uniformly (1.0 / k), following the implementation from"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "694,697c720,726", 
        "remove": [
            "< distributions over topics (\"theta\").This is the parameter to a symmetric Dirichlet distribution, where larger values", 
            "< mean more smoothing (more regularization).If set to -1, then docConcentration is set automatically.", 
            "<  (default = -1 = automatic)Optimizer-specific parameter settings:EMValue should be > 1.0default = (50 / k) + 1, where 50/k is common in LDA libraries and +1 follows", 
            "<       Asuncion et al. (2009), who recommend a +1 adjustment for EM.OnlineValue should be >= 0default = (1.0 / k), following the implementation from"
        ]
    }, 
    {
        "add": [
            ">         LDAModel extends Saveable"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "14c14", 
        "remove": [
            "<         LDAModel extends AnyRef"
        ]
    }, 
    {
        "add": [
            ">           Saveable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "25c25", 
        "remove": [
            "<           AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LDAModelSaveableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "46c46", 
        "remove": [
            "<                   LDAModelAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">       Return the topics described by weighted terms.Return the topics described by weighted terms."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "82,84c82", 
        "remove": [
            "<       Return the topics described by weighted terms.Return the topics described by weighted terms.This limits the number of terms per topic.", 
            "< This is approximate; it may not return exactly the top-weighted terms for each topic.", 
            "< To get a more precise set of top terms, increase maxTermsPerTopic."
        ]
    }, 
    {
        "add": [
            ">         docConcentration: Vector", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").This is the parameter to a Dirichlet distribution.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">", 
            ">         formatVersion: String", 
            ">", 
            ">", 
            ">       Current version of model save/load format.Current version of model save/load format. Attributesprotected Definition ClassesSaveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">", 
            ">         gammaShape: Double", 
            ">", 
            ">", 
            ">       Shape parameter for random initialization of variational parameter gamma.Shape parameter for random initialization of variational parameter gamma.", 
            "> Used for variational inference for perplexity and other test-time computations.", 
            ">  Attributesprotected", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "97a96,139", 
        "remove": []
    }, 
    {
        "add": [
            ">         save(sc: SparkContext, path: String): Unit", 
            ">", 
            ">", 
            ">       Save this model to the given path.Save this model to the given path.This saves:human-readable (JSON) model metadata to path/metadata/Parquet formatted data to path/data/The model may be loaded using Loader.load.", 
            "> scSpark context used to save model data.pathPath specifying the directory in which to save this model.", 
            ">              If the directory already exists, this method throws an exception.", 
            ">  Definition ClassesSaveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">", 
            ">         topicConcentration: Double", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.This is the parameter to a symmetric Dirichlet distribution.Note: The topics' distributions over terms are called \"beta\" in the original LDA paper", 
            "> by Blei et al., but are called \"phi\" in many later papers such as Asuncion et al., 2009.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LDAModel.html.raw:", 
        "location": "110a153,185", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from Saveable", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "465a541,542", 
        "remove": []
    }, 
    {
        "add": [
            "> than the DistributedLDAModel. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "21,22c21", 
        "remove": [
            "< than the DistributedLDAModel.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">           Serializable, Serializable, LDAModel, Saveable, AnyRef, Any"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "27c26", 
        "remove": [
            "<           Serializable, Serializable, LDAModel, AnyRef, Any"
        ]
    }, 
    {
        "add": [
            ">                   LocalLDAModelSerializableSerializableLDAModelSaveableAnyRefAny"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "45c44", 
        "remove": [
            "<                   LocalLDAModelSerializableSerializableLDAModelAnyRefAny"
        ]
    }, 
    {
        "add": [
            ">       Return the topics described by weighted terms.Return the topics described by weighted terms."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "180,182c179", 
        "remove": [
            "<       Return the topics described by weighted terms.Return the topics described by weighted terms.This limits the number of terms per topic.", 
            "< This is approximate; it may not return exactly the top-weighted terms for each topic.", 
            "< To get a more precise set of top terms, increase maxTermsPerTopic."
        ]
    }, 
    {
        "add": [
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         docConcentration: Vector", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").Concentration parameter (commonly named \"alpha\") for the prior placed on documents'", 
            "> distributions over topics (\"theta\").This is the parameter to a Dirichlet distribution.", 
            ">  Definition ClassesLocalLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "208a206,221", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         formatVersion: String", 
            ">", 
            ">", 
            ">       Current version of model save/load format.Current version of model save/load format. Attributesprotected Definition ClassesLocalLDAModel \u2192 Saveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         gammaShape: Double", 
            ">", 
            ">", 
            ">       Shape parameter for random initialization of variational parameter gamma.Shape parameter for random initialization of variational parameter gamma.", 
            "> Used for variational inference for perplexity and other test-time computations.", 
            ">  Attributesprotected[org.apache.spark.mllib.clustering] Definition ClassesLocalLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "253a267,294", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         logLikelihood(documents: RDD[(Long, Vector)]): Double", 
            ">", 
            ">", 
            ">       Calculates a lower bound on the log likelihood of the entire corpus.Calculates a lower bound on the log likelihood of the entire corpus.See Equation (16) in original Online LDA paper.", 
            "> documentstest corpus to use for calculating log likelihoodreturnsvariational lower bound on the log likelihood of the entire corpus", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         logPerplexity(documents: RDD[(Long, Vector)]): Double", 
            ">", 
            ">", 
            ">       Calculate an upper bound bound on perplexity.Calculate an upper bound bound on perplexity.  (Lower is better.)", 
            "> See Equation (16) in original Online LDA paper.", 
            "> documentstest corpus to use for calculating perplexityreturnsVariational upper bound on log perplexity per token.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "305a347,377", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         save(sc: SparkContext, path: String): Unit", 
            ">", 
            ">", 
            ">       Save this model to the given path.Save this model to the given path.This saves:human-readable (JSON) model metadata to path/metadata/Parquet formatted data to path/data/The model may be loaded using Loader.load.", 
            "> scSpark context used to save model data.pathPath specifying the directory in which to save this model.", 
            ">              If the directory already exists, this method throws an exception.", 
            ">  Definition ClassesLocalLDAModel \u2192 Saveable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "344a417,432", 
        "remove": []
    }, 
    {
        "add": [
            ">         val", 
            ">", 
            ">", 
            ">         topicConcentration: Double", 
            ">", 
            ">", 
            ">       Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.Concentration parameter (commonly named \"beta\" or \"eta\") for the prior placed on topics'", 
            "> distributions over terms.This is the parameter to a symmetric Dirichlet distribution.Note: The topics' distributions over terms are called \"beta\" in the original LDA paper", 
            "> by Blei et al., but are called \"phi\" in many later papers such as Asuncion et al., 2009.", 
            ">  Definition ClassesLocalLDAModel \u2192 LDAModel", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         topicDistributions(documents: RDD[(Long, Vector)]): RDD[(Long, Vector)]", 
            ">", 
            ">", 
            ">       Predicts the topic mixture distribution for each document (often called \"theta\" in the", 
            "> literature).Predicts the topic mixture distribution for each document (often called \"theta\" in the", 
            "> literature).  Returns a vector of zeros for an empty document.This uses a variational approximation following Hoffman et al. (2010), where the approximate", 
            "> distribution is called \"gamma.\"  Technically, this method returns this approximation \"gamma\"", 
            "> for each document.documentsdocuments to predict topic mixture distributions forreturnsAn RDD of (document ID, topic mixture distribution for document)", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         val", 
            ">", 
            ">", 
            ">         topics: Matrix", 
            ">", 
            ">", 
            ">       Inferred topics (vocabSize x k matrix).", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/LocalLDAModel.html.raw:", 
        "location": "371a460,507", 
        "remove": []
    }, 
    {
        "add": [
            ">               Inherited from Saveable", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html.raw:", 
        "location": "467a604,605", 
        "remove": []
    }, 
    {
        "add": [
            ">         getOptimzeAlpha: Boolean", 
            ">", 
            ">", 
            ">       Optimize alpha, indicates whether alpha (Dirichlet parameter for document-topic distribution)", 
            "> will be optimized during training.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html.raw:", 
        "location": "278a279,292", 
        "remove": []
    }, 
    {
        "add": [
            ">         setOptimzeAlpha(optimizeAlpha: Boolean): OnlineLDAOptimizer.this.type", 
            ">", 
            ">", 
            ">       Sets whether to optimize alpha parameter during training.Sets whether to optimize alpha parameter during training.Default: false", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/package.html.raw:", 
        "location": "393a408,421", 
        "remove": []
    }, 
    {
        "add": [
            ">         LDAModel extends Saveable"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/package.html.raw:", 
        "location": "138c138", 
        "remove": [
            "<         LDAModel extends AnyRef"
        ]
    }, 
    {
        "add": [
            ">         DistributedLDAModel extends Loader[DistributedLDAModel]", 
            ">", 
            ">", 
            ">        Annotations", 
            ">                 @Experimental()", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         object", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/package.html.raw:", 
        "location": "248a249,264", 
        "remove": []
    }, 
    {
        "add": [
            ">         LDAUtils", 
            ">", 
            ">", 
            ">       Utility methods for LDA.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         object", 
            ">", 
            ">", 
            ">         LocalLDAModel extends Loader[LocalLDAModel] with Serializable", 
            ">", 
            ">", 
            ">        Annotations", 
            ">                 @Experimental()", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         object", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/clustering/PowerIterationClustering.html.raw:", 
        "location": "290a307,335", 
        "remove": []
    }, 
    {
        "add": [
            ">         run(graph: Graph[Double, Double]): PowerIterationClusteringModel", 
            ">", 
            ">", 
            ">       Run the PIC algorithm on Graph.Run the PIC algorithm on Graph.", 
            "> graphan affinity matrix represented as graph, which is the matrix A in the PIC paper.", 
            ">              The similarity sij represented as the edge between vertices (i, j) must", 
            ">              be nonnegative. This is a symmetric matrix and hence sij = sji. For", 
            ">              any (i, j) with nonzero similarity, there should be either (i, j, sij)", 
            ">              or (j, i, sji) in the input. Tuples with i = j are ignored, because we", 
            ">              assume sij = 0.0.", 
            "> returnsa PowerIterationClusteringModel that contains the clustering result", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/evaluation/RegressionMetrics.html.raw:", 
        "location": "351a352,372", 
        "remove": []
    }, 
    {
        "add": [
            ">       Returns the variance explained by regression.Returns the variance explained by regression.", 
            "> explainedVariance = \\sum_i (\\hat{y_i} - \\bar{y})^2 / n See alsohttps://en.wikipedia.org/wiki/Fraction_of_variance_unexplained"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/evaluation/RegressionMetrics.html.raw:", 
        "location": "221,223c221,222", 
        "remove": [
            "<       Returns the explained variance regression score.Returns the explained variance regression score.", 
            "< explainedVariance = 1 - variance(y - \\hat{y}) / variance(y)", 
            "< Reference: http://en.wikipedia.org/wiki/Explained_variation"
        ]
    }, 
    {
        "add": [
            ">       Returns R2, the unadjusted coefficient of determination.Returns R2, the unadjusted coefficient of determination. See alsohttp://en.wikipedia.org/wiki/Coefficient_of_determination"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/feature/package.html.raw:", 
        "location": "531,532c530", 
        "remove": [
            "<       Returns R2, the coefficient of determination.Returns R2, the coefficient of determination.", 
            "< Reference: http://en.wikipedia.org/wiki/Coefficient_of_determination"
        ]
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/feature/Word2VecModel.html.raw:", 
        "location": "239d238", 
        "remove": [
            "<"
        ]
    }, 
    {
        "add": [
            "> Word2Vec model Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/feature/Word2VecModel.html.raw:", 
        "location": "19,20c19", 
        "remove": [
            "< Word2Vec model", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">               Instance Constructors", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         new", 
            ">", 
            ">", 
            ">         Word2VecModel(model: Map[String, Array[Float]])", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth$$FreqItemset.html.raw:", 
        "location": "61a61,76", 
        "remove": []
    }, 
    {
        "add": [
            ">  Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth$$FreqItemset.html.raw:", 
        "location": "18a19", 
        "remove": []
    }, 
    {
        "add": [
            ">       Returns items in a Java List.Returns items in a Java List.", 
            ">  Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth$.html.raw:", 
        "location": "300c301,303", 
        "remove": [
            "<       Returns items in a Java List."
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "21a22", 
        "remove": []
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "26a27", 
        "remove": []
    }, 
    {
        "add": [
            "> as the input data}.Constructs a default instance with default parameters {minSupport: 0.3, numPartitions: same"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "81a83", 
        "remove": []
    }, 
    {
        "add": [
            ">  Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "82a85,86", 
        "remove": []
    }, 
    {
        "add": [
            ">  Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "506a511", 
        "remove": []
    }, 
    {
        "add": [
            ">       Sets the minimal support level (default: 0.3).Sets the minimal support level (default: 0.3).", 
            ">  Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowth.html.raw:", 
        "location": "520c525,527", 
        "remove": [
            "<       Sets the minimal support level (default: 0.3)."
        ]
    }, 
    {
        "add": [
            ">       Sets the number of partitions used by parallel FP-growth (default: same as input data).Sets the number of partitions used by parallel FP-growth (default: same as input data).", 
            ">  Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowthModel.html.raw:", 
        "location": "533c540,542", 
        "remove": [
            "<       Sets the number of partitions used by parallel FP-growth (default: same as input data)."
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/FPGrowthModel.html.raw:", 
        "location": "21a22", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         generateAssociationRules(confidence: Double): RDD[Rule[Item]]", 
            ">", 
            ">", 
            ">       Generates association rules for the Items in freqItemsets.Generates association rules for the Items in freqItemsets.confidenceminimal confidence of the rules produced Since1.5.0", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/package.html.raw:", 
        "location": "243a245,258", 
        "remove": []
    }, 
    {
        "add": [
            ">         AssociationRules extends Logging with Serializable", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/package.html.raw:", 
        "location": "45a46,58", 
        "remove": []
    }, 
    {
        "add": [
            ">         class", 
            ">", 
            ">", 
            ">         PrefixSpan extends Logging with Serializable", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         class", 
            ">", 
            ">", 
            ">         PrefixSpanModel[Item] extends Serializable", 
            ">", 
            ">", 
            ">       Model fitted by PrefixSpan", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/package.html.raw:", 
        "location": "68a82,107", 
        "remove": []
    }, 
    {
        "add": [
            ">         AssociationRules extends Serializable", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         object", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/fpm/package.html.raw:", 
        "location": "78a118,130", 
        "remove": []
    }, 
    {
        "add": [
            ">         object", 
            ">", 
            ">", 
            ">         PrefixSpan extends Logging with Serializable", 
            ">", 
            ">", 
            ">        Annotations", 
            ">                 @Experimental()", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/DenseMatrix.html.raw:", 
        "location": "89a142,157", 
        "remove": []
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         numActives: Int", 
            ">", 
            ">", 
            ">       Find the number of values stored explicitly.Find the number of values stored explicitly. These values can be zero as well.", 
            ">  Definition ClassesDenseMatrix \u2192 Matrix", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/DenseMatrix.html.raw:", 
        "location": "414a415,428", 
        "remove": []
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         numNonzeros: Int", 
            ">", 
            ">", 
            ">       Find the number of non-zero active values.Find the number of non-zero active values.", 
            ">  Definition ClassesDenseMatrix \u2192 Matrix", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/DenseVector.html.raw:", 
        "location": "427a442,455", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         argmax: Int", 
            ">", 
            ">", 
            ">       Find the index of a maximal element.Find the index of a maximal element.  Returns the first maximal element in case of a tie.", 
            "> Returns -1 if vector has length 0.", 
            ">  Definition ClassesDenseVector \u2192 Vector", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/distributed/RowMatrix.html.raw:", 
        "location": "167a168,182", 
        "remove": []
    }, 
    {
        "add": [
            ">         tallSkinnyQR(computeQ: Boolean = false): QRDecomposition[RowMatrix, Matrix]", 
            ">", 
            ">", 
            ">       Compute QR decomposition for RowMatrix.Compute QR decomposition for RowMatrix. The implementation is designed to optimize the QR", 
            "> decomposition (factorization) for the RowMatrix of a tall and skinny shape.", 
            "> Reference:", 
            ">  Paul G. Constantine, David F. Gleich. \"Tall and skinny QR factorizations in MapReduce", 
            ">  architectures\"  (http://dx.doi.org/10.1145/1996092.1996103)", 
            "> computeQwhether to computeQreturnsQRDecomposition(Q, R), Q = null if computeQ = false.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/Matrix.html.raw:", 
        "location": "714a715,733", 
        "remove": []
    }, 
    {
        "add": [
            ">         numActives: Int", 
            ">", 
            ">", 
            ">       Find the number of values stored explicitly.Find the number of values stored explicitly. These values can be zero as well.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/Matrix.html.raw:", 
        "location": "103a104,117", 
        "remove": []
    }, 
    {
        "add": [
            ">         numNonzeros: Int", 
            ">", 
            ">", 
            ">       Find the number of non-zero active values.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/package.html.raw:", 
        "location": "116a131,143", 
        "remove": []
    }, 
    {
        "add": [
            ">         QRDecomposition[UType, VType](Q: UType, R: VType) extends Product with Serializable", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Represents QR factors.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         case class", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/SparseMatrix.html.raw:", 
        "location": "84a85,98", 
        "remove": []
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         numActives: Int", 
            ">", 
            ">", 
            ">       Find the number of values stored explicitly.Find the number of values stored explicitly. These values can be zero as well.", 
            ">  Definition ClassesSparseMatrix \u2192 Matrix", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/SparseMatrix.html.raw:", 
        "location": "433a434,447", 
        "remove": []
    }, 
    {
        "add": [
            ">         def", 
            ">", 
            ">", 
            ">         numNonzeros: Int", 
            ">", 
            ">", 
            ">       Find the number of non-zero active values.Find the number of non-zero active values.", 
            ">  Definition ClassesSparseMatrix \u2192 Matrix", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/SparseVector.html.raw:", 
        "location": "446a461,474", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         argmax: Int", 
            ">", 
            ">", 
            ">       Find the index of a maximal element.Find the index of a maximal element.  Returns the first maximal element in case of a tie.", 
            "> Returns -1 if vector has length 0.", 
            ">  Definition ClassesSparseVector \u2192 Vector", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/linalg/Vector.html.raw:", 
        "location": "168a169,183", 
        "remove": []
    }, 
    {
        "add": [
            ">         argmax: Int", 
            ">", 
            ">", 
            ">       Find the index of a maximal element.Find the index of a maximal element.  Returns the first maximal element in case of a tie.", 
            "> Returns -1 if vector has length 0.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         abstract", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/optimization/GradientDescent$.html.raw:", 
        "location": "77a78,92", 
        "remove": []
    }, 
    {
        "add": [
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         runMiniBatchSGD(data: RDD[(Double, Vector)], gradient: Gradient, updater: Updater, stepSize: Double, numIterations: Int, regParam: Double, miniBatchFraction: Double, initialWeights: Vector, convergenceTol: Double): (Vector, Array[Double])", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/optimization/GradientDescent$.html.raw:", 
        "location": "469a470,482", 
        "remove": []
    }, 
    {
        "add": [
            "> dataInput data for SGD. RDD of the set of data examples, each of", 
            ">             the form (label, [feature values]).gradientGradient object (used to compute the gradient of the loss function of", 
            ">                 one single data example)updaterUpdater function to actually perform a gradient step in a given direction.stepSizeinitial step size for the first stepnumIterationsnumber of iterations that SGD should be run.regParamregularization parameterminiBatchFractionfraction of the input data set that should be used for", 
            ">                          one iteration of SGD. Default value 1.0.convergenceTolMinibatch iteration will end before numIterations if the relative", 
            ">                       difference between the current weight and the previous weight is less", 
            ">                       than this value. In measuring convergence, L2 norm is calculated.", 
            ">                       Default value 0.001. Must be between 0.0 and 1.0 inclusively.returnsA tuple containing two elements. The first element is a column matrix containing"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/optimization/GradientDescent.html.raw:", 
        "location": "475,479c488,494", 
        "remove": [
            "< data- Input data for SGD. RDD of the set of data examples, each of", 
            "<               the form (label, [feature values]).gradient- Gradient object (used to compute the gradient of the loss function of", 
            "<                   one single data example)updater- Updater function to actually perform a gradient step in a given direction.stepSize- initial step size for the first stepnumIterations- number of iterations that SGD should be run.regParam- regularization parameterminiBatchFraction- fraction of the input data set that should be used for", 
            "<                            one iteration of SGD. Default value 1.0.", 
            "< returnsA tuple containing two elements. The first element is a column matrix containing"
        ]
    }, 
    {
        "add": [
            ">         setConvergenceTol(tolerance: Double): GradientDescent.this.type", 
            ">", 
            ">", 
            ">       Set the convergence tolerance.Set the convergence tolerance. Default 0.001", 
            "> convergenceTol is a condition which decides iteration termination.", 
            "> The end of iteration is decided based on below logic.", 
            "> - If the norm of the new solution vector is >1, the diff of solution vectors", 
            ">   is compared to relative tolerance which means normalizing by the norm of", 
            ">   the new solution vector.", 
            "> - If the norm of the new solution vector is <=1, the diff of solution vectors", 
            ">   is compared to absolute tolerance which is not normalizing.", 
            "> Must be between 0.0 and 1.0 inclusively.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "480a481,502", 
        "remove": []
    }, 
    {
        "add": [
            ">           Top-level methods for calling Alternating Least Squares (ALS) matrix factorization. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "18c18", 
        "remove": [
            "<           Top-level methods for calling Alternating Least Squares (ALS) matrix factorization."
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20) Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "329c329", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01) Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "349c349", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation into Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "369c369", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation into"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoseedrandom seed Since0.9.1"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "389c389", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoseedrandom seed"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20) Since0.8.1"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "410c410", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)alphaconfidence parameter Since0.8.1"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "430c430", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)alphaconfidence parameter"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoalphaconfidence parameter Since0.8.1"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/ALS$.html.raw:", 
        "location": "450c450", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoalphaconfidence parameter"
        ]
    }, 
    {
        "add": [
            "> ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoalphaconfidence parameterseedrandom seed Since0.8.1"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel$.html.raw:", 
        "location": "470c470", 
        "remove": [
            "< ratingsRDD of (userID, productID, rating) pairsranknumber of features to useiterationsnumber of iterations of ALS (recommended: 10-20)lambdaregularization factor (recommended: 0.01)blockslevel of parallelism to split computation intoalphaconfidence parameterseedrandom seed"
        ]
    }, 
    {
        "add": [
            ">            Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel$.html.raw:", 
        "location": "17a18", 
        "remove": []
    }, 
    {
        "add": [
            "> scSpark context used for loading model files.pathPath specifying the directory to which the model was saved.returnsModel instance Definition ClassesMatrixFactorizationModel \u2192 LoaderSince1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "258,259c259,260", 
        "remove": [
            "< scSpark context used for loading model files.pathPath specifying the directory to which the model was saved.returnsModel instance", 
            "<  Definition ClassesMatrixFactorizationModel \u2192 Loader"
        ]
    }, 
    {
        "add": [
            ">  Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "19a20", 
        "remove": []
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "83d83", 
        "remove": [
            "<"
        ]
    }, 
    {
        "add": [
            ">       Java-friendly version of MatrixFactorizationModel.predict.Java-friendly version of MatrixFactorizationModel.predict. Since1.2.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "499c499,500", 
        "remove": [
            "<       Java-friendly version of MatrixFactorizationModel.predict."
        ]
    }, 
    {
        "add": [
            "> usersProductsRDD of (user, product) pairs.returnsRDD of Ratings. Since0.9.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "515c516", 
        "remove": [
            "< usersProductsRDD of (user, product) pairs.returnsRDD of Ratings."
        ]
    }, 
    {
        "add": [
            ">       Predict the rating of one user for one product.Predict the rating of one user for one product. Since0.8.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "529c530,531", 
        "remove": [
            "<       Predict the rating of one user for one product."
        ]
    }, 
    {
        "add": [
            ">  recommended the product is. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "574c576", 
        "remove": [
            "<  recommended the product is."
        ]
    }, 
    {
        "add": [
            "> rating field. Semantics of score is same as recommendProducts API Since1.4.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "591c593", 
        "remove": [
            "< rating field. Semantics of score is same as recommendProducts API"
        ]
    }, 
    {
        "add": [
            ">  recommended the user is. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "611c613", 
        "remove": [
            "<  recommended the user is."
        ]
    }, 
    {
        "add": [
            "> rating field. Semantics of score is same as recommendUsers API Since1.4.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html.raw:", 
        "location": "628c630", 
        "remove": [
            "< rating field. Semantics of score is same as recommendUsers API"
        ]
    }, 
    {
        "add": [
            ">              If the directory already exists, this method throws an exception. Definition ClassesMatrixFactorizationModel \u2192 SaveableSince1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/recommendation/Rating.html.raw:", 
        "location": "644,645c646,647", 
        "remove": [
            "<              If the directory already exists, this method throws an exception.", 
            "<  Definition ClassesMatrixFactorizationModel \u2192 Saveable"
        ]
    }, 
    {
        "add": [
            ">           A more compact class to represent a rating than Tuple3[Int, Int, Double]. Since0.8.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html.raw:", 
        "location": "18c18", 
        "remove": [
            "<           A more compact class to represent a rating than Tuple3[Int, Int, Double]."
        ]
    }, 
    {
        "add": [
            ">         setConvergenceTol(tolerance: Double): StreamingLinearRegressionWithSGD.this.type", 
            ">", 
            ">", 
            ">       Set the convergence tolerance.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html.raw:", 
        "location": "591a592,604", 
        "remove": []
    }, 
    {
        "add": [
            ">       Set the initial weights."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html.raw:", 
        "location": "595c608", 
        "remove": [
            "<       Set the initial weights.Set the initial weights. Default: [0.0, 0.0]."
        ]
    }, 
    {
        "add": [
            ">         Since1.3.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html.raw:", 
        "location": "25a26", 
        "remove": []
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html.raw:", 
        "location": "87d87", 
        "remove": [
            "<"
        ]
    }, 
    {
        "add": [
            ">       Returns the log-density of this multivariate Gaussian at given point, xReturns the log-density of this multivariate Gaussian at given point, x Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html.raw:", 
        "location": "282c282,283", 
        "remove": [
            "<       Returns the log-density of this multivariate Gaussian at given point, x"
        ]
    }, 
    {
        "add": [
            ">       Returns density of this multivariate Gaussian at given point, xReturns density of this multivariate Gaussian at given point, x Since1.3.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/distribution/MultivariateGaussian.html.raw:", 
        "location": "347c348,349", 
        "remove": [
            "<       Returns density of this multivariate Gaussian at given point, x"
        ]
    }, 
    {
        "add": [], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/KernelDensity.html.raw:", 
        "location": "366d367", 
        "remove": [
            "<"
        ]
    }, 
    {
        "add": [
            ">         Since1.4.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/KernelDensity.html.raw:", 
        "location": "26a27", 
        "remove": []
    }, 
    {
        "add": [
            ">       Estimates probability density function at the given array of points.Estimates probability density function at the given array of points. Since1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/KernelDensity.html.raw:", 
        "location": "224c225,226", 
        "remove": [
            "<       Estimates probability density function at the given array of points."
        ]
    }, 
    {
        "add": [
            ">       Sets the bandwidth (standard deviation) of the Gaussian kernel (default: 1.0).Sets the bandwidth (standard deviation) of the Gaussian kernel (default: 1.0). Since1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/KernelDensity.html.raw:", 
        "location": "334c336,337", 
        "remove": [
            "<       Sets the bandwidth (standard deviation) of the Gaussian kernel (default: 1.0)."
        ]
    }, 
    {
        "add": [
            ">       Sets the sample to use for density estimation (for Java users).Sets the sample to use for density estimation (for Java users). Since1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/KernelDensity.html.raw:", 
        "location": "347c350,351", 
        "remove": [
            "<       Sets the sample to use for density estimation (for Java users)."
        ]
    }, 
    {
        "add": [
            ">       Sets the sample to use for density estimation.Sets the sample to use for density estimation. Since1.4.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "360c364,365", 
        "remove": [
            "<       Sets the sample to use for density estimation."
        ]
    }, 
    {
        "add": [
            "> to have time complexity O(nnz) instead of O(n) for each column. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "25,26c25", 
        "remove": [
            "< to have time complexity O(nnz) instead of O(n) for each column.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "28a28", 
        "remove": []
    }, 
    {
        "add": [
            "> sampleThe sample in dense/sparse vector format to be added into this summarizer.returnsThis MultivariateOnlineSummarizer object. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "169c169", 
        "remove": [
            "< sampleThe sample in dense/sparse vector format to be added into this summarizer.returnsThis MultivariateOnlineSummarizer object."
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "215,216c215,216", 
        "remove": [
            "<       Sample size.Sample size.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "313,314c313,314", 
        "remove": [
            "<       Maximum value of each column.Maximum value of each column.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "327,328c327,328", 
        "remove": [
            "<       Sample mean vector.Sample mean vector.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            "> otherThe other MultivariateOnlineSummarizer to be merged.returnsThis MultivariateOnlineSummarizer object. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "343c343", 
        "remove": [
            "< otherThe other MultivariateOnlineSummarizer to be merged.returnsThis MultivariateOnlineSummarizer object."
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "357,358c357,358", 
        "remove": [
            "<       Minimum value of each column.Minimum value of each column.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.2.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "384,386c384,385", 
        "remove": [
            "<       L1 norm of each column", 
            "< L1 norm of each column", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.2.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "399,401c398,399", 
        "remove": [
            "<       Euclidean magnitude of each column", 
            "< Euclidean magnitude of each column", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html.raw:", 
        "location": "440,441c438,439", 
        "remove": [
            "<       Number of nonzero elements (including explicitly presented zero values) in each column.Number of nonzero elements (including explicitly presented zero values) in each column.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">        Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummarySince1.1.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "480,481c478,479", 
        "remove": [
            "<       Sample variance vector.Sample variance vector. Should return a zero vector if the sample size is 1.", 
            "<  Definition ClassesMultivariateOnlineSummarizer \u2192 MultivariateStatisticalSummary"
        ]
    }, 
    {
        "add": [
            ">           Trait for multivariate statistical summary of a data matrix. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "18c18", 
        "remove": [
            "<           Trait for multivariate statistical summary of a data matrix."
        ]
    }, 
    {
        "add": [
            ">       Sample size.Sample size. Since1.0.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "78c78,79", 
        "remove": [
            "<       Sample size."
        ]
    }, 
    {
        "add": [
            ">       Maximum value of each column.Maximum value of each column. Since1.0.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "91c92,93", 
        "remove": [
            "<       Maximum value of each column."
        ]
    }, 
    {
        "add": [
            ">       Sample mean vector.Sample mean vector. Since1.0.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "104c106,107", 
        "remove": [
            "<       Sample mean vector."
        ]
    }, 
    {
        "add": [
            ">       Minimum value of each column.Minimum value of each column. Since1.0.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "117c120,121", 
        "remove": [
            "<       Minimum value of each column."
        ]
    }, 
    {
        "add": [
            ">       L1 norm of each columnL1 norm of each column Since1.2.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "130c134", 
        "remove": [
            "<       L1 norm of each column"
        ]
    }, 
    {
        "add": [
            ">       Euclidean magnitude of each columnEuclidean magnitude of each column Since1.2.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "144c148", 
        "remove": [
            "<       Euclidean magnitude of each column"
        ]
    }, 
    {
        "add": [
            ">       Number of nonzero elements (including explicitly presented zero values) in each column.Number of nonzero elements (including explicitly presented zero values) in each column. Since1.0.0", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html.raw:", 
        "location": "158c162,163", 
        "remove": [
            "<       Number of nonzero elements (including explicitly presented zero values) in each column."
        ]
    }, 
    {
        "add": [
            ">       Sample variance vector.Sample variance vector. Should return a zero vector if the sample size is 1. Since1.0.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "171c176", 
        "remove": [
            "<       Sample variance vector.Sample variance vector. Should return a zero vector if the sample size is 1."
        ]
    }, 
    {
        "add": [
            "> API for statistical functions in MLlib. Annotations"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "19,20c19", 
        "remove": [
            "< API for statistical functions in MLlib.", 
            "<  Annotations"
        ]
    }, 
    {
        "add": [
            ">         Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "22a22", 
        "remove": []
    }, 
    {
        "add": [
            ">         The order of the elements in the returned array reflects the order of input features. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "164c164", 
        "remove": [
            "<         The order of the elements in the returned array reflects the order of input features."
        ]
    }, 
    {
        "add": [
            ">         the method used, and the null hypothesis. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "182c182", 
        "remove": [
            "<         the method used, and the null hypothesis."
        ]
    }, 
    {
        "add": [
            ">         the method used, and the null hypothesis. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "200c200", 
        "remove": [
            "<         the method used, and the null hypothesis."
        ]
    }, 
    {
        "add": [
            ">         the method used, and the null hypothesis. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "221c221", 
        "remove": [
            "<         the method used, and the null hypothesis."
        ]
    }, 
    {
        "add": [
            "> Xan RDD[Vector] for which column-wise summary statistics are to be computed.returnsMultivariateStatisticalSummary object containing column-wise summary statistics. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "255c255", 
        "remove": [
            "< Xan RDD[Vector] for which column-wise summary statistics are to be computed.returnsMultivariateStatisticalSummary object containing column-wise summary statistics."
        ]
    }, 
    {
        "add": [
            ">       Java-friendly version of corr()Java-friendly version of corr() Since1.4.1", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "269c269,270", 
        "remove": [
            "<       Java-friendly version of corr()"
        ]
    }, 
    {
        "add": [
            ">         specified method. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "287c288", 
        "remove": [
            "<         specified method."
        ]
    }, 
    {
        "add": [
            ">       Java-friendly version of corr()Java-friendly version of corr() Since1.4.1", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "301c302,303", 
        "remove": [
            "<       Java-friendly version of corr()"
        ]
    }, 
    {
        "add": [
            "> xRDD[Double] of the same cardinality as y.yRDD[Double] of the same cardinality as x.returnsA Double containing the Pearson correlation between the two input RDD[Double]s Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "317c319", 
        "remove": [
            "< xRDD[Double] of the same cardinality as y.yRDD[Double] of the same cardinality as x.returnsA Double containing the Pearson correlation between the two input RDD[Double]s"
        ]
    }, 
    {
        "add": [
            ">               Supported: pearson (default), spearmanreturnsCorrelation matrix comparing columns in X. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "337c339", 
        "remove": [
            "<               Supported: pearson (default), spearmanreturnsCorrelation matrix comparing columns in X."
        ]
    }, 
    {
        "add": [
            "> Xan RDD[Vector] for which the correlation matrix is to be computed.returnsPearson correlation matrix comparing columns in X. Since1.1.0"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/Statistics$.html.raw:", 
        "location": "353c355", 
        "remove": [
            "< Xan RDD[Vector] for which the correlation matrix is to be computed.returnsPearson correlation matrix comparing columns in X."
        ]
    }, 
    {
        "add": [
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         kolmogorovSmirnovTest(data: RDD[Double], distName: String, params: Double*): KolmogorovSmirnovTestResult", 
            ">", 
            ">", 
            ">       Convenience function to conduct a one-sample, two-sided Kolmogorov-Smirnov test for probability", 
            "> distribution equality.Convenience function to conduct a one-sample, two-sided Kolmogorov-Smirnov test for probability", 
            "> distribution equality. Currently supports the normal distribution, taking as parameters", 
            "> the mean and standard deviation.", 
            "> (distName = \"norm\")dataan RDD[Double] containing the sample of data to testdistNamea String name for a theoretical distributionparamsDouble* specifying the parameters to be used for the theoretical distributionreturnsorg.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult object containing test", 
            ">        statistic, p-value, and null hypothesis.", 
            ">  Annotations", 
            ">                 @varargs()", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         kolmogorovSmirnovTest(data: RDD[Double], cdf: (Double) \u21d2 Double): KolmogorovSmirnovTestResult", 
            ">", 
            ">", 
            ">       Conduct the two-sided Kolmogorov-Smirnov (KS) test for data sampled from a", 
            "> continuous distribution.Conduct the two-sided Kolmogorov-Smirnov (KS) test for data sampled from a", 
            "> continuous distribution. By comparing the largest difference between the empirical cumulative", 
            "> distribution of the sample data and the theoretical distribution we can provide a test for the", 
            "> the null hypothesis that the sample data comes from that theoretical distribution.", 
            "> For more information on KS Test:dataan RDD[Double] containing the sample of data to testcdfa Double => Double function to calculate the theoretical CDF at a given valuereturnsorg.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult object containing test", 
            ">        statistic, p-value, and null hypothesis.", 
            ">  See alsohttps://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/test/package.html.raw:", 
        "location": "443a446,488", 
        "remove": []
    }, 
    {
        "add": [
            ">         class", 
            ">", 
            ">", 
            ">         KolmogorovSmirnovTestResult extends TestResult[Int]", 
            ">", 
            ">", 
            ">       :: Experimental ::", 
            "> Object containing the test results for the Kolmogorov-Smirnov test.", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/stat/test/TestResult.html.raw:", 
        "location": "56a57,70", 
        "remove": []
    }, 
    {
        "add": [
            ">           ChiSqTestResult, KolmogorovSmirnovTestResult"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/tree/configuration/BoostingStrategy.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           ChiSqTestResult"
        ]
    }, 
    {
        "add": [
            ">                      then stop.  Ignored when", 
            ">                      org.apache.spark.mllib.tree.GradientBoostedTrees.run() is used."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/tree/configuration/BoostingStrategy.html.raw:", 
        "location": "25c25,26", 
        "remove": [
            "<                      then stop. Ignored when run is used."
        ]
    }, 
    {
        "add": [
            ">                      then stop.  Ignored when", 
            ">                      org.apache.spark.mllib.tree.GradientBoostedTrees.run() is used."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/tree/configuration/BoostingStrategy.html.raw:", 
        "location": "86c87,88", 
        "remove": [
            "<                      then stop. Ignored when run is used."
        ]
    }, 
    {
        "add": [
            ">                      then stop.  Ignored when", 
            ">                      org.apache.spark.mllib.tree.GradientBoostedTrees.run() is used."
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/tree/configuration/Strategy$.html.raw:", 
        "location": "503c505,506", 
        "remove": [
            "<                      then stop. Ignored when run is used."
        ]
    }, 
    {
        "add": [
            ">         defaultStrategy(algo: Algo): Strategy"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/tree/configuration/Strategy$.html.raw:", 
        "location": "173c173", 
        "remove": [
            "<         defaultStategy(algo: Algo): Strategy"
        ]
    }, 
    {
        "add": [
            ">               Deprecated Value Members", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">", 
            ">         def", 
            ">", 
            ">", 
            ">         defaultStategy(algo: Algo): Strategy", 
            ">", 
            ">", 
            ">        Annotations", 
            ">                 @deprecated", 
            ">", 
            ">         Deprecated(Since version 1.5.0) Use Strategy.defaultStrategy instead.", 
            ">", 
            ">"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/util/Loader.html.raw:", 
        "location": "403a404,422", 
        "remove": []
    }, 
    {
        "add": [
            ">           DecisionTreeModel, DistributedLDAModel, GaussianMixtureModel, GradientBoostedTreesModel, IsotonicRegressionModel, KMeansModel, LassoModel, LinearRegressionModel, LocalLDAModel, LogisticRegressionModel, MatrixFactorizationModel, NaiveBayesModel, PowerIterationClusteringModel, RandomForestModel, RidgeRegressionModel, SVMModel, Word2VecModel"
        ], 
        "filename": "1.4.2/org/apache/spark/mllib/util/Saveable.html.raw:", 
        "location": "28c28", 
        "remove": [
            "<           DecisionTreeModel, GaussianMixtureModel, GradientBoostedTreesModel, IsotonicRegressionModel, KMeansModel, LassoModel, LinearRegressionModel, LogisticRegressionModel, MatrixFactorizationModel, NaiveBayesModel, PowerIterationClusteringModel, RandomForestModel, RidgeRegressionModel, SVMModel, Word2VecModel"
        ]
    }
]